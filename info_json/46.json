{
  "id": 46,
  "repo": "relay",
  "issue_url": "https://github.com/getsentry/relay/issues/4090",
  "pr_url": "https://github.com/getsentry/relay/pull/4112",
  "issue_description": "### Flakiness Type\n\nAssertion failure\n\n### Name of Test\n\ntests/integration/test_healthchecks.py::test_readiness_not_enough_memory_bytes\n\n### Link to Test Run\n\nhttps://github.com/getsentry/relay/actions/runs/11126418454/job/30916575904\n\n### Details\n\n```\n____________________ test_readiness_not_enough_memory_bytes ____________________\n[gw0] linux -- Python 3.11.10 /home/runner/work/relay/relay/.venv/bin/python3\nTraceback (most recent call last):\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 341, in from_call\n    result: Optional[TResult] = func()\n                                ^^^^^^\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 262, in <lambda>\n    lambda: ihook(item=item, **kwds), when=when, reraise=reraise\n            ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/pluggy/_hooks.py\", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/pluggy/_manager.py\", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/pluggy/_callers.py\", line 182, in _multicall\n    return outcome.get_result()\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/pluggy/_result.py\", line 100, in get_result\n    raise exc.with_traceback(exc.__traceback__)\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/pluggy/_callers.py\", line 103, in _multicall\n    res = hook_impl.function(*args)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 177, in pytest_runtest_call\n    raise e\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/_pytest/runner.py\", line 169, in pytest_runtest_call\n    item.runtest()\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 1792, in runtest\n    self.ihook.pytest_pyfunc_call(pyfuncitem=self)\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/pluggy/_hooks.py\", line 513, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/pluggy/_manager.py\", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/pluggy/_callers.py\", line 139, in _multicall\n    raise exception.with_traceback(exception.__traceback__)\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/pluggy/_callers.py\", line 103, in _multicall\n    res = hook_impl.function(*args)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/relay/relay/.venv/lib/python3.11/site-packages/_pytest/python.py\", line 194, in pytest_pyfunc_call\n    result = testfunction(**testargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/runner/work/relay/relay/tests/integration/test_healthchecks.py\", line 96, in test_readiness_not_enough_memory_bytes\n    error = str(mini_sentry.test_failures.pop(0))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nIndexError: pop from empty list\n```",
  "files_changed": [
    {
      "filename": "tests/integration/fixtures/mini_sentry.py",
      "status": "modified",
      "patch": "@@ -6,7 +6,7 @@\n import re\n import uuid\n from copy import deepcopy\n-from queue import Queue\n+from queue import Empty, Queue\n \n import pytest\n \n@@ -41,8 +41,7 @@ def __init__(self, server_address, app):\n         self.captured_events = Queue()\n         self.captured_outcomes = Queue()\n         self.captured_metrics = Queue()\n-        self.test_failures = []\n-        self.reraise_test_failures = True\n+        self.test_failures = Queue()\n         self.hits = {}\n         self.known_relays = {}\n         self.fail_on_relay_error = True\n@@ -64,9 +63,21 @@ def hit(self, path):\n         self.hits.setdefault(path, 0)\n         self.hits[path] += 1\n \n+    def current_test_failures(self):\n+        \"\"\"Return current list of test failures without waiting for additional failures.\"\"\"\n+        try:\n+            while failure := self.test_failures.get_nowait():\n+                yield failure\n+        except Empty:\n+            return\n+\n+    def clear_test_failures(self):\n+        \"\"\"Reset test failures to an empty queue.\"\"\"\n+        self.test_failures = Queue()\n+\n     def format_failures(self):\n         s = \"\"\n-        for route, error in self.test_failures:\n+        for route, error in self.current_test_failures():\n             s += f\"> {route}: {error}\\n\"\n         return s\n \n@@ -296,7 +307,7 @@ def store_internal_error_event():\n \n         if event is not None and sentry.fail_on_relay_error:\n             error = AssertionError(\"Relay sent us event: \" + get_error_message(event))\n-            sentry.test_failures.append((\"/api/666/envelope/\", error))\n+            sentry.test_failures.put((\"/api/666/envelope/\", error))\n \n         return jsonify({\"event_id\": uuid.uuid4().hex})\n \n@@ -452,10 +463,10 @@ def fail(e):\n         raise e\n \n     def reraise_test_failures():\n-        if sentry.test_failures and sentry.reraise_test_failures:\n+        if not sentry.test_failures.empty():\n             pytest.fail(\n                 \"{n} exceptions happened in mini_sentry:\\n\\n{failures}\".format(\n-                    n=len(sentry.test_failures), failures=sentry.format_failures()\n+                    n=sentry.test_failures.qsize(), failures=sentry.format_failures()\n                 )\n             )\n "
    },
    {
      "filename": "tests/integration/fixtures/relay.py",
      "status": "modified",
      "patch": "@@ -1,5 +1,6 @@\n import json\n import os\n+from queue import Queue\n import sys\n import uuid\n import signal\n@@ -211,11 +212,11 @@ def inner(\n             relay.wait_relay_health_check()\n \n             # Filter out health check failures, which can happen during startup\n-            mini_sentry.test_failures = [\n-                f\n-                for f in mini_sentry.test_failures\n-                if \"Health check probe\" not in str(f)\n-            ]\n+            filtered_test_failures = Queue()\n+            for f in mini_sentry.current_test_failures():\n+                if \"Health check probe\" not in str(f):\n+                    filtered_test_failures.put(f)\n+            mini_sentry.test_failures = filtered_test_failures\n \n         return relay\n "
    },
    {
      "filename": "tests/integration/test_basic.py",
      "status": "modified",
      "patch": "@@ -110,7 +110,7 @@ def get_project_config():\n         relay.shutdown(sig=signal.SIGINT)\n         pytest.raises(queue.Empty, lambda: mini_sentry.captured_events.get(timeout=1))\n \n-        failures = mini_sentry.test_failures\n+        failures = mini_sentry.current_test_failures()\n         assert failures\n \n         # we are expecting at least a dropped unfinished future error\n@@ -121,7 +121,7 @@ def get_project_config():\n                 dropped_unfinished_error_found = True\n         assert dropped_unfinished_error_found\n     finally:\n-        mini_sentry.test_failures.clear()\n+        mini_sentry.clear_test_failures()\n \n \n @pytest.mark.parametrize(\"trailing_slash\", [True, False])"
    },
    {
      "filename": "tests/integration/test_config.py",
      "status": "modified",
      "patch": "@@ -14,9 +14,9 @@ def test_invalid_kafka_config_should_fail(mini_sentry, relay_with_processing):\n     relay = relay_with_processing(options=options, wait_health_check=False)\n     assert relay.wait_for_exit() != 0\n \n-    error = str(mini_sentry.test_failures.pop(0))\n+    error = str(mini_sentry.test_failures.get_nowait())\n     assert \"__unknown\" in error\n-    error = str(mini_sentry.test_failures.pop(0))\n+    error = str(mini_sentry.test_failures.get_nowait())\n     assert \"profiles\" in error.lower()\n \n \n@@ -26,5 +26,5 @@ def test_invalid_topics_raise_error(mini_sentry, relay_with_processing):\n     relay = relay_with_processing(options=options, wait_health_check=False)\n     assert relay.wait_for_exit() != 0\n \n-    error = str(mini_sentry.test_failures.pop(0))\n+    error = str(mini_sentry.test_failures.get_nowait())\n     assert \"failed to validate the topic with name\" in error"
    },
    {
      "filename": "tests/integration/test_envelope.py",
      "status": "modified",
      "patch": "@@ -465,12 +465,12 @@ def get_project_config():\n \n         include_global = True\n         # Clear errors because we log error when we request global config yet we dont receive it.\n-        assert len(mini_sentry.test_failures) > 0\n-        assert {str(e) for _, e in mini_sentry.test_failures} == {\n+        assert not mini_sentry.test_failures.empty()\n+        assert {str(e) for _, e in mini_sentry.current_test_failures()} == {\n             \"Relay sent us event: global config missing in upstream response\"\n         }\n     finally:\n-        mini_sentry.test_failures.clear()\n+        mini_sentry.clear_test_failures()\n \n     envelopes = []\n     # Check that we received exactly {envelope_qty} envelopes."
    },
    {
      "filename": "tests/integration/test_healthchecks.py",
      "status": "modified",
      "patch": "@@ -53,7 +53,7 @@ def test_readiness(mini_sentry, relay):\n         mini_sentry.app.view_functions[\"check_challenge\"] = original_check_challenge\n         relay.wait_relay_health_check()\n     finally:\n-        mini_sentry.test_failures.clear()\n+        mini_sentry.clear_test_failures()\n \n     response = relay.get(\"/api/relay/healthcheck/ready/\")\n     assert response.status_code == 200\n@@ -69,7 +69,7 @@ def test_readiness_flag(mini_sentry, relay):\n         response = wait_get(relay, \"/api/relay/healthcheck/ready/\")\n         assert response.status_code == 200\n     finally:\n-        mini_sentry.test_failures.clear()\n+        mini_sentry.clear_test_failures()\n \n \n def test_readiness_proxy(mini_sentry, relay):\n@@ -88,12 +88,11 @@ def test_readiness_not_enough_memory_bytes(mini_sentry, relay):\n     )\n \n     response = wait_get(relay, \"/api/relay/healthcheck/ready/\")\n-    time.sleep(1.0)  # Wait for error\n-    error = str(mini_sentry.test_failures.pop(0))\n+    error = str(mini_sentry.test_failures.get(timeout=2))\n     assert \"Not enough memory\" in error and \">= 42\" in error\n-    error = str(mini_sentry.test_failures.pop(0))\n+    error = str(mini_sentry.test_failures.get(timeout=1))\n     assert \"Health check probe 'system memory'\" in error\n-    error = str(mini_sentry.test_failures.pop(0))\n+    error = str(mini_sentry.test_failures.get(timeout=1))\n     assert \"Health check probe 'spool health'\" in error\n     assert response.status_code == 503\n \n@@ -105,12 +104,12 @@ def test_readiness_not_enough_memory_percent(mini_sentry, relay):\n         wait_health_check=False,\n     )\n     response = wait_get(relay, \"/api/relay/healthcheck/ready/\")\n-    time.sleep(1.0)  # Wait for error\n-    error = str(mini_sentry.test_failures.pop(0))\n+\n+    error = str(mini_sentry.test_failures.get(timeout=2))\n     assert \"Not enough memory\" in error and \">= 1.00%\" in error\n-    error = str(mini_sentry.test_failures.pop(0))\n+    error = str(mini_sentry.test_failures.get(timeout=1))\n     assert \"Health check probe 'system memory'\" in error\n-    error = str(mini_sentry.test_failures.pop(0))\n+    error = str(mini_sentry.test_failures.get(timeout=1))\n     assert \"Health check probe 'spool health'\" in error\n     assert response.status_code == 503\n \n@@ -123,8 +122,8 @@ def test_readiness_depends_on_aggregator_being_full(mini_sentry, relay):\n     )\n \n     response = wait_get(relay, \"/api/relay/healthcheck/ready/\")\n-    time.sleep(0.3)  # Wait for error\n-    error = str(mini_sentry.test_failures.pop())\n+\n+    error = str(mini_sentry.test_failures.get(timeout=1))\n     assert \"Health check probe 'aggregator'\" in error\n     assert response.status_code == 503\n \n@@ -140,20 +139,19 @@ def test_readiness_depends_on_aggregator_being_full_after_metrics(mini_sentry, r\n \n     for _ in range(100):\n         response = wait_get(relay, \"/api/relay/healthcheck/ready/\")\n-        print(response, response.status_code)\n         if response.status_code == 503:\n-            error = str(mini_sentry.test_failures.pop())\n-            assert \"Health check probe 'aggregator'\" in error\n-            error = str(mini_sentry.test_failures.pop())\n+            error = str(mini_sentry.test_failures.get(timeout=1))\n             assert \"aggregator limit exceeded\" in error\n+            error = str(mini_sentry.test_failures.get(timeout=1))\n+            assert \"Health check probe 'aggregator'\" in error\n             return\n         time.sleep(0.1)\n \n     assert False, \"health check never failed\"\n \n \n def test_readiness_disk_spool(mini_sentry, relay):\n-    mini_sentry.reraise_test_failures = False\n+    mini_sentry.fail_on_relay_error = False\n     temp = tempfile.mkdtemp()\n     dbfile = os.path.join(temp, \"buffer.db\")\n "
    },
    {
      "filename": "tests/integration/test_metrics.py",
      "status": "modified",
      "patch": "@@ -1182,7 +1182,7 @@ def test_transaction_metrics_not_extracted_on_unsupported_version(\n     tx_consumer.assert_empty()\n \n     if unsupported_version < TRANSACTION_EXTRACT_MIN_SUPPORTED_VERSION:\n-        error = str(mini_sentry.test_failures.pop(0))\n+        error = str(mini_sentry.test_failures.get_nowait())\n         assert \"Processing Relay outdated\" in error\n \n     metrics_consumer.assert_empty()"
    },
    {
      "filename": "tests/integration/test_projectconfigs.py",
      "status": "modified",
      "patch": "@@ -260,11 +260,11 @@ def test_unparsable_project_config(mini_sentry, relay):\n \n     def assert_clear_test_failures():\n         try:\n-            assert {str(e) for _, e in mini_sentry.test_failures} == {\n+            assert {str(e) for _, e in mini_sentry.current_test_failures()} == {\n                 f\"Relay sent us event: error fetching project state {public_key}: invalid type: integer `99`, expected a string\",\n             }\n         finally:\n-            mini_sentry.test_failures.clear()\n+            mini_sentry.clear_test_failures()\n \n     # Event is not propagated, relay logs an error:\n     relay.send_event(project_key)\n@@ -343,11 +343,11 @@ def test_cached_project_config(mini_sentry, relay):\n     try:\n         relay.send_event(project_key)\n         time.sleep(0.5)\n-        assert {str(e) for _, e in mini_sentry.test_failures} == {\n+        assert {str(e) for _, e in mini_sentry.current_test_failures()} == {\n             f\"Relay sent us event: error fetching project state {public_key}: invalid type: integer `99`, expected a string\",\n         }\n     finally:\n-        mini_sentry.test_failures.clear()\n+        mini_sentry.clear_test_failures()\n \n \n def test_get_global_config(mini_sentry, relay):"
    },
    {
      "filename": "tests/integration/test_query.py",
      "status": "modified",
      "patch": "@@ -38,7 +38,7 @@ def test_local_project_config(mini_sentry, relay):\n     dsn_key = config[\"publicKeys\"][0][\"publicKey\"]\n \n     relay.wait_relay_health_check()\n-    mini_sentry.test_failures.clear()\n+    mini_sentry.clear_test_failures()\n \n     relay.send_event(project_id, dsn_key=dsn_key)\n     event = mini_sentry.captured_events.get(timeout=1).get_event()\n@@ -148,11 +148,10 @@ def get_project_config():\n         assert event[\"logentry\"] == {\"formatted\": \"Hello, World!\"}\n         assert retry_count == 3\n \n-        if mini_sentry.test_failures:\n-            for _, error in mini_sentry.test_failures:\n-                assert isinstance(error, (socket.error, AssertionError))\n+        for _, error in mini_sentry.current_test_failures():\n+            assert isinstance(error, (socket.error, AssertionError))\n     finally:\n-        mini_sentry.test_failures.clear()\n+        mini_sentry.clear_test_failures()\n \n \n def test_query_retry_maxed_out(mini_sentry, relay_with_processing, events_consumer):\n@@ -190,18 +189,18 @@ def get_project_config():\n     )\n \n     # No error messages yet\n-    assert not mini_sentry.test_failures\n+    assert mini_sentry.test_failures.empty()\n \n     try:\n         relay.send_event(42)\n         time.sleep(query_timeout)\n \n         assert request_count == 1 + RETRIES\n-        assert {str(e) for _, e in mini_sentry.test_failures} == {\n+        assert {str(e) for _, e in mini_sentry.current_test_failures()} == {\n             \"Relay sent us event: error fetching project states: upstream request returned error 500 Internal Server Error: no error details\",\n         }\n     finally:\n-        mini_sentry.test_failures.clear()\n+        mini_sentry.clear_test_failures()\n \n \n @pytest.mark.parametrize(\"disabled\", (True, False))"
    },
    {
      "filename": "tests/integration/test_store.py",
      "status": "modified",
      "patch": "@@ -193,7 +193,7 @@ def configure_static_project(dir):\n     assert event[\"logentry\"] == {\"formatted\": \"Hello, World!\"}\n \n     sleep(1)  # Regression test: Relay tried to issue a request for 0 states\n-    if mini_sentry.test_failures:\n+    if not mini_sentry.test_failures.empty():\n         raise AssertionError(\n             f\"Exceptions happened in mini_sentry: {mini_sentry.format_failures()}\"\n         )\n@@ -230,15 +230,15 @@ def test_store_with_low_memory(mini_sentry, relay):\n         pytest.raises(queue.Empty, lambda: mini_sentry.captured_events.get(timeout=1))\n \n         found_queue_error = False\n-        for _, error in mini_sentry.test_failures:\n+        for _, error in mini_sentry.current_test_failures():\n             assert isinstance(error, AssertionError)\n             if \"failed to queue envelope\" in str(error):\n                 found_queue_error = True\n                 break\n \n         assert found_queue_error\n     finally:\n-        mini_sentry.test_failures.clear()\n+        mini_sentry.clear_test_failures()\n \n \n def test_store_max_concurrent_requests(mini_sentry, relay):\n@@ -954,7 +954,7 @@ def server_error(*args, **kwargs):\n         assert event[\"logentry\"] == {\"formatted\": \"Hello, World!\"}\n     finally:\n         # Relay reports authentication errors, which is fine.\n-        mini_sentry.test_failures.clear()\n+        mini_sentry.clear_test_failures()\n \n \n def test_events_are_retried(relay, mini_sentry):\n@@ -1181,7 +1181,7 @@ def counted_check_challenge(*args, **kwargs):\n     evt.clear()\n     assert evt.wait(2)\n     # clear authentication errors accumulated until now\n-    mini_sentry.test_failures.clear()\n+    mini_sentry.clear_test_failures()\n     # check that we have had some auth that succeeded\n     auth_count_3 = counter[0]\n     assert auth_count_2 < auth_count_3\n@@ -1250,7 +1250,7 @@ def counted_check_challenge(*args, **kwargs):\n     # to be sure verify that we have only been called once (after failing)\n     assert counter[1] == 1\n     # clear authentication errors accumulated until now\n-    mini_sentry.test_failures.clear()\n+    mini_sentry.clear_test_failures()\n \n \n def test_buffer_events_during_outage(relay, mini_sentry):"
    }
  ],
  "fix_category": NaN,
  "root_cause_category": NaN,
  "root_cause_subcategory": "!Rust (CI)"
}