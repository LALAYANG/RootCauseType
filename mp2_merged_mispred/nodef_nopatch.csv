"id","ground_truth","GPT5_predicted","GPT4_predicted","correct_label","possible_reason_GPT5","possible_reason_GPT4","description"
"10","Time","Network","Test order dependency","","","","This PR allows SparkQA (i.e. Jenkins) to report in its posts to GitHub what category of test failed, if one can be determined.  The failure categories are: - general failure - RAT checks failed - Scala style checks failed - Python style checks failed - Build failed - Spark unit tests failed - PySpark unit tests failed - MiMa checks failed  This PR also fixes the diffing logic used to determine if a patch introduces new classes."
"11","Time","Unordered collections","Concurrency","","","","Since python does not have a library for max heap and usual tricks like inverting values etc.. does not work for all cases.   We have our own implementation of max heap."
"15","Time","Network","Network","","","","Add address and/or port to errors where applicable for better reporting.  See joyent/node#7005 and #16"
"16","Test order dependency","I/O","I/O","","","","Given my home-directory is `/Users/rocko` - and I have a file named `npm.json` in it and also a repository with name `npm`, which is a folder for the node-module.  When try to require the `/Users/rocko/npm/index.js` two direcotry levels down in the npm folder (e.g. `/Users/rocko/npm/test/tap`) with require(""../../"") node will load `/Users/rocko/npm/index.json`.  When I use require(""../.."") node will load `/Users/rocko/npm.json` which is fixed by this commit.  Original PR: https://github.com/joyent/node/pull/7094"
"17","Resource leak","Time","OS","","","","No out-of-tree patches, yay!  R=@indutny"
"19","Resource leak","Network","Network","","","","- **Google Hangouts Video**: http://www.youtube.com/watch?v=Z0KHYPlFI3E - **GitHub Issue**: https://github.com/iojs/io.js/issues/300 - **Original Minutes Google Doc**: https://docs.google.com/document/d/1HDUayYxTjolYZhu_hGm9hc-6MGAwWrHlNGT2Zo708ck"
"20","Async wait","OS","Network","","","","There was a couple of errors on the dev script preventing it to work properly. I also merged this with the open pr I had for adding `next/css`"
"27","Async wait","Unordered collections","Network","","","","@StephanEwen, @aljoscha: Can someone please confirm that this is the place to disable the POJO types?  There are various issues when working with POJOs in the Java API, for example [1].  [1] https://mail-archives.apache.org/mod_mbox/incubator-flink-dev/201407.mbox/%3C53D96049.1060509%40cse.uta.edu%3E"
"30","Async wait","I/O","OS","","","","We currently use `package.json` for our configuration. I think we should move away from using `package.json` and use something like `next.config.js` since it gives us more power than JSON.    An example is the issue for custom Webpack support: https://github.com/zeit/next.js/issues/40.  With a config like this you could do this for example:    ```js  // next.config.js    export default {    webpack: (webpackConfig) => {      const newConfig = { ...webpackConfig };      newConfig.module.preloaders.push({ test: /\.js$/, loader: 'eslint-loader' });      return newConfig;    },    cdn: false  }  ```    Which is in my opinion better than creating a new file for webpack since this is more centralised. This does however still give users the option to use different files, for the webpack example:    ```js  // next.config.js    export default {    webpack: require('./webpack').default,    cdn: false  }  ```    These are just my thoughts, I found out that I needed a sort of config file in `.js` when starting a PR for this project. Very curious what others think of this üòÑ."
"31","Async wait","OS","Floating point operations","","","","The StringComparator now works on serialized data.  To this end new string read/write/copy/compare methods were introduced, which use a variable-length encoding for the characters.  ~~key-points:~~   ~~\- The most significant bits are written/read first.~~   ~~\- The first 2 bits of the character are used to encode the size of the character.~~  ~~\- A character is at most 3 Bytes big.~~  Additionally, the StringSerializer now has full unicode support. ~~i couldn't find a unicode character that ~~uses more than 22 bits, as such 3 Bytes should be sufficient.~~"
"32","Concurrency","Time","Time","","","","[PR Linked Issue] Platforms: linux, rocm, slow      This test was disabled because it is failing in CI. See [recent examples](https://hud.pytorch.org/flakytest?name=test_aoti_fx_add&suite=AOTFxirTestCase&limit=100) and the most recent trunk [workflow logs](https://github.com/pytorch/pytorch/runs/49795173420).    Over the past 6 hours, it has been determined flaky in 10 workflow(s) with 20 failures and 10 successes.    **Debugging instructions (after clicking on the recent samples link):**   DO NOT ASSUME THINGS ARE OKAY IF THE CI IS GREEN. We now shield flaky tests from developers so CI will thus be green but it will be harder to parse the logs.   To find relevant log snippets:   1. Click on the workflow logs linked above   2. Click on the Test step of the job so that it is expanded. Otherwise, the grepping will not work.   3. Grep for `test_aoti_fx_add`   4. There should be several instances run (as flaky tests are rerun in CI) from which you can study the logs.         Test file path: `inductor/test_fxir_backend.py`    For all disabled tests (by GitHub issue), see https://hud.pytorch.org/disabled.  cc @clee2000 @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @ipiszy @chenyang78 @kadeng @muchulee8 @amjames @chauhang @aakhundov @coconutruben"
"33","Test order dependency","Unordered collections","Unordered collections","","","","Stack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom): * __->__ #143878 * #143865  Summary: Test erroneously assumed that input/output sizes are same and that all states are matchable.  Fixes issue #143798  Test Plan: Test passes  Reviewers Test passes  cc @H-Huang @awgu @kwen2501 @wanchaol @fegin @fduwjj @wz337 @wconstab @d4l3k"
"35","Floating point operations","Concurrency","Floating point operations","","","","[PR Linked Issue] Platforms: linux    This test was disabled because it is failing in CI. See [recent examples](https://hud.pytorch.org/flakytest?name=test_grad_with_manual_interleaved_ScheduleClass0_use_new_runtime_True&suite=ScheduleTest&limit=100) and the most recent trunk [workflow logs](https://github.com/pytorch/pytorch/runs/42919034022).    Over the past 3 hours, it has been determined flaky in 7 workflow(s) with 7 failures and 7 successes.    **Debugging instructions (after clicking on the recent samples link):**   DO NOT ASSUME THINGS ARE OKAY IF THE CI IS GREEN. We now shield flaky tests from developers so CI will thus be green but it will be harder to parse the logs.   To find relevant log snippets:   1. Click on the workflow logs linked above   2. Click on the Test step of the job so that it is expanded. Otherwise, the grepping will not work.   3. Grep for `test_grad_with_manual_interleaved_ScheduleClass0_use_new_runtime_True`   4. There should be several instances run (as flaky tests are rerun in CI) from which you can study the logs.        <details><summary>Sample error message</summary>  ``` Traceback (most recent call last):   File ""/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/testing/_internal/common_distributed.py"", line 1721, in wrapper     raise rv AssertionError: Tensor-likes are not close!  Mismatched elements: 158 / 512 (30.9%) Greatest absolute difference: 0.0002696812152862549 at index (331,) (up to 4e-05 allowed) Greatest relative difference: 0.09954891353845596 at index (176,) (up to 1e-05 allowed)  To execute this test, run the following from the base repo dir:     python test/distributed/pipelining/test_schedule_multiproc.py ScheduleTest.test_grad_with_manual_interleaved_ScheduleClass0_use_new_runtime_True  This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0 ```  </details>     Test file path: `distributed/pipelining/test_schedule_multiproc.py`    For all disabled tests (by GitHub issue), see https://hud.pytorch.org/disabled.  cc @H-Huang @awgu @wanchaol @fegin @fduwjj @wz337 @wconstab @d4l3k @clee2000"
"38","Floating point operations","Floating point operations","Randomness","","","","[PR Linked Issue] ```  Falsifying example: test_gpu_data_iterator(      n_samples_per_batch=57, n_features=1, n_batches=9, subsample=False,  )  ```    It's caused by one different element in the generated cuts.  We need to change the test to adapt to the differences in the models."
"40","Network","Async wait","Network","","","","[PR Linked Issue]  | Reason | <code>client-proxy/test-https-proxy-request-invalid-char-in-url</code> | | - | :- | | Type | JS_TEST_FAILURE | | Failed PR | 3 ([https://github.com/nodejs/node/pull/59587/](https://ci.nodejs.org/job/node-test-pull-request/68946/), [https://github.com/nodejs/node/pull/59734/](https://ci.nodejs.org/job/node-test-pull-request/69013/), [https://github.com/nodejs/node/pull/59717/](https://ci.nodejs.org/job/node-test-pull-request/69014/)) | | Appeared | [vm-efv4j](https://ci.nodejs.org/job/node-test-commit-osx/nodes=osx13-x64/66595/console), [vm-a49f1](https://ci.nodejs.org/job/node-test-commit-osx/nodes=osx13-x64/66594/console), [vm-yy37e](https://ci.nodejs.org/job/node-test-commit-osx/nodes=osx13-x64/66523/console) | | First CI | https://ci.nodejs.org/job/node-test-pull-request/68946/ | | Last CI | https://ci.nodejs.org/job/node-test-pull-request/69014/ |  <details> <summary><a href=""https://ci.nodejs.org/job/node-test-commit-osx/nodes=osx13-x64/66595/console"">Example</a></summary>  ``` not ok 4333 client-proxy/test-https-proxy-request-invalid-char-in-url   ---   duration_ms: 413.52500   severity: fail   exitcode: 1   stack: |-     #6 eneded response for: 'https://local\rhost:55386/carriage-return-in-host'     #5 eneded response for: 'https://local\r\nhost:55386/crlf-in-host'     #4 eneded response for: 'https://local\nhost:55386/newline-in-host'     #3 eneded response for: 'https://localhost:5\r5386/carriage-return-in-port'     #2 eneded response for: 'https://localhost:5\n5386/newline-in-port'     #1 eneded response for: 'https://localhost:5\r\n5386/crlf-in-port'     node:assert:147       throw new AssertionError(obj);       ^          AssertionError [ERR_ASSERTION]: Expected values to be strictly deep-equal:     + actual - expected          + Set(8) {     - Set(6) {         {     +     error: Error [ERR_STREAM_WRITE_AFTER_END]: write after end     +         at _write (node:internal/streams/writable:487:11)     +         at Writable.write (node:internal/streams/writable:508:10)     +      ... ``` </details>  From https://github.com/nodejs/reliability/blob/main/reports/2025-09-03.md"
"42","Async wait","Time","Time","","","","[PR Linked Issue] ### Test    `test/parallel/test-zlib-brotli-16GB.js`    ### Platform    AIX    ### Console output    ```console  17:07:37 not ok 3588 parallel/test-zlib-brotli-16GB  17:07:37   ---  17:07:37   duration_ms: 412.84800  17:07:37   severity: fail  17:07:37   exitcode: 1  17:07:37   stack: |-  17:07:37     node:assert:126  17:07:37       throw new AssertionError(obj);  17:07:37       ^  17:07:37       17:07:37     AssertionError [ERR_ASSERTION]: Expected values to be strictly equal:  17:07:37       17:07:37     0 !== 1  17:07:37       17:07:37         at Timeout.<anonymous> (/home/iojs/build/workspace/node-test-commit-aix/nodes/aix72-ppc64/test/parallel/test-zlib-brotli-16GB.js:21:3)  17:07:37         at Timeout._onTimeout (/home/iojs/build/workspace/node-test-commit-aix/nodes/aix72-ppc64/test/common/index.js:476:15)  17:07:37         at listOnTimeout (node:internal/timers:573:17)  17:07:37         at process.processTimers (node:internal/timers:514:7) {  17:07:37       generatedMessage: true,  17:07:37       code: 'ERR_ASSERTION',  17:07:37       actual: 0,  17:07:37       expected: 1,  17:07:37       operator: 'strictEqual'  17:07:37     }  17:07:37       17:07:37     Node.js v21.6.3-pre  17:07:37   ...  ```      ### Build links    - https://ci.nodejs.org/job/node-test-commit-aix/50223/nodes=aix72-ppc64/console    ### Additional information    _No response_"
"45","Concurrency","Resource leak","Resource leak","","","","### Motivation    Running ClusterMigrationTest could fail with OOME.  When investigating the problem, it showed up that ClusterMigrationTest's TestBroker inner class doesn't clean up resources properly. The admin clients weren't closed.    ### Modifications    * Call `super.internalCleanup()` in the `cleanup` method.  * Close admin clients in the test cleanup method    ### Documentation    <!-- DO NOT REMOVE THIS SECTION. CHECK THE PROPER BOX ONLY. -->    - [ ] `doc` <!-- Your PR contains doc changes. -->  - [ ] `doc-required` <!-- Your PR changes impact docs and you will update later -->  - [x] `doc-not-needed` <!-- Your PR changes do not impact docs -->  - [ ] `doc-complete` <!-- Docs have been already added -->"
"47","Async wait","Concurrency","Concurrency","","","","This was straightforward to reproduce locally, both with and without scheduler-side queuing. Unsure why on CI it seems to only fail without queuing.    ![image](https://github.com/dask/distributed/assets/6213168/ae93bdb1-0624-4543-8b0d-cd003e0570f1)    Now the test is rock solid (ran 200 times per CI environment)."
"48","Concurrency","Time","Network","","","","<!--  Hey! You're PRing? Cool!  Please be sure to check out our contribution guide (https://github.com/python-telegram-bot/python-telegram-bot/blob/master/.github/CONTRIBUTING.rst).  Especially, please have a look at the check list for PRs (https://github.com/python-telegram-bot/python-telegram-bot/blob/master/.github/CONTRIBUTING.rst#check-list-for-prs). Feel free to copy (parts of) the checklist to the PR description to remind you or the maintainers of open points or if you have questions on anything.  -->"
"52","Resource leak","Async wait","Resource leak","","","","### Rationale for this change Fixing flaky bloom filter memory check test  ### What changes are included in this PR? Added an additional runtime.GC() call to ensure the releases are called."
"54","Async wait","Test order dependency","Test order dependency","","","","Resolves a couple of issues with running Flatpages tests by... - Creating an example_site fixture - Overriding project SITE_ID setting to 1 - Normalizing the use of the hardcoded (1) site_id to settings.SITE_ID"
"55","Async wait","Test order dependency","Network","","","","Used the `render` shortcut in the ""using a form in a view"" example to ensure that the CSRF is properly enabled."
"65","Time","Time","Test order dependency","","","","- [x] closes #14626    - [x] tests added / passed   - [x] passes ``git diff upstream/master | flake8 --diff``   - [ ] whatsnew entry"
"66","OS","Time","Test order dependency","","","","xref #14626"
"67","Resource leak","Time","Time","","","","[PR Linked Issue] These tests are the same ones that run against other analytics DBs, but for some reason when we run them against Presto/Hive we get false positives (or are they false negatives? ü§î) at a much greater rate. These tests also seem to take much longer to run, which may be related.    If we can get to the bottom of this it will massively improve the experience of contributing to Superset.    #### How to reproduce the bug    Run CI a few times.    ### Expected results    CI should pass if the PR hasn't introduced any bugs.    ### Actual results    It fails a lot. Often multiple times in a row, with different tests.    ### Additional context    I want to start putting together a list of the tests that have failed, to see if there is some sort of pattern. Feel free to add new entries to this list (only if you are certain that it really is a false positive!). Please also link to a relevant line of the GitHub Action where the test failed.    - [ERROR tests/integration_tests/dashboards/filter_state/api_tests.py::test_delete_not_owner](https://github.com/apache/superset/runs/4524150250?check_suite_focus=true#step:8:2363)  - [ERROR tests/integration_tests/security_tests.py::TestRolePermission::test_admin_permissions](https://github.com/apache/superset/runs/4525283552?check_suite_focus=true#step:8:2420)"
"68","Network","Async wait","Async wait","","","","## Summary    This is my guess as to the source of the resolver flake, based on information and extensive debugging from @zanieb. In short, if we rely on `self.index.packages` as a source of truth during error reporting, we open ourselves up to a source of non-determinism, because we fetch package metadata asynchronously in the background while we solve -- so packages _could_ be included in or excluded from the index depending on the order in which those requests are returned.    So, instead, we now track the set of packages that _were_ visited by the solver. Visiting a package _requires_ that we wait for its metadata to be available. By limiting analysis to those packages that were visited during solving, we are faithfully representing the state of the solver at the time of failure.    Closes #863"
"70","Concurrency","Time","Time","","","","This test has recently become flaky on windows CI, and before investigating further, see if it's just because the CI machines are overloaded and subprocesses are slower on windows."
"72","Async wait","Time","Test order dependency","","","","<!-- Thank you for submitting a Pull Request. Please: * Read our Pull Request guidelines:   https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests * Associate an issue with the Pull Request. * Ensure that the code is up-to-date with the `main` branch. * Include a description of the proposed changes and how to test them. -->"
"74","Network","Async wait","Async wait","","","","[PR Linked Issue] https://dev.azure.com/monacotools/Monaco/_build/results?buildId=314193&view=logs&j=9833cdaa-2e92-5f8d-56a8-239fd18fd628&t=efbaf268-cf98-50c2-bb3c-7950770fd6bc&l=749  ```   1) vscode API - terminal        Terminal          environmentVariableCollection            should have collection variables apply to terminals immediately after setting:      Error: Timeout: b1~b2~ should be printed after 20 seconds. Did not pass accept function       at poll (/Users/runner/work/1/s/extensions/vscode-api-tests/src/utils.ts:176:10)       at Context.<anonymous> (/Users/runner/work/1/s/extensions/vscode-api-tests/src/singlefolder-tests/terminal.test.ts:775:5)    2) vscode API - terminal        Terminal          environmentVariableCollection            should have collection variables apply to environment variables that don't exist:      Error: Timeout: ~b2~ should be printed after 20 seconds. Did not pass accept function       at poll (/Users/runner/work/1/s/extensions/vscode-api-tests/src/utils.ts:176:10)       at Context.<anonymous> (/Users/runner/work/1/s/extensions/vscode-api-tests/src/singlefolder-tests/terminal.test.ts:820:5)    3) vscode API - terminal        Terminal          environmentVariableCollection            should respect clearing entries:      Error: Timeout: ~b1~ should be printed after 20 seconds. Did not pass accept function       at poll (/Users/runner/work/1/s/extensions/vscode-api-tests/src/utils.ts:176:10)       at Context.<anonymous> (/Users/runner/work/1/s/extensions/vscode-api-tests/src/singlefolder-tests/terminal.test.ts:862:5)   ```"
"89","Async wait","Async wait","Network","","","","https://scans.gradle.com/s/bfgjiqwioneey/tests/task/:profiler:test/details/com.splunk.opentelemetry.profiler.snapshot.LongRunningBackgroundTaskTest/traceBackgroundThreadProfilingContinuesAfterEntrySpanEnds()?top-execution=1"
"90","Async wait","Time","Test order dependency","","","","<!--  Thank you for your contribution!  Unless your change is trivial, please create an issue to discuss the change before creating a PR.  -->    ### Describe your changes:    Fixes <issue-number>    <!--  Short blurb explaining:  - What changes did you make?  - Why did you make them?  - How did you test your changes?  -->    I worked on ... because ...    <!-- For frontend related change, please add screenshots and/or videos of your changes preview! -->    #  ### Type of change:  <!-- You should choose 1 option and delete options that aren't relevant -->  - [ ] Bug fix  - [ ] Improvement  - [ ] New feature  - [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)  - [ ] Documentation    #  ### Checklist:  <!-- add an x in [] if done, don't mark items that you didn't do !-->  - [x] I have read the [**CONTRIBUTING**](https://docs.open-metadata.org/developers/contribute) document.  - [ ] My PR title is `Fixes <issue-number>: <short explanation>`  - [ ] I have commented on my code, particularly in hard-to-understand areas.   - [ ] For JSON Schema changes: I updated the migration scripts or explained why it is not needed.    <!-- Based on the type(s) of your change, uncomment the required checklist üëá -->    <!-- Bug fix  - [ ] I have added a test that covers the exact scenario we are fixing. For complex issues, comment the issue number in the test for future reference.  -->    <!-- Improvement  - [ ] I have added tests around the new logic.  - [ ] For connector/ingestion changes: I updated the documentation.  -->    <!-- New feature  - [ ] The issue properly describes why the new feature is needed, what's the goal, and how we are building it. Any discussion      or decision-making process is reflected in the issue.  - [ ] I have updated the documentation.  - [ ] I have added tests around the new logic.  -->    <!-- Breaking change  - [ ] I have added the tag `Backward-Incompatible-Change`.  -->"
"93","Concurrency","OS","Network","","","","Reference: https://spec.openapis.org/arazzo/v1.0.0#literals    This enables basic parsing of string literals as values in conditions, which in Arazzo are contained in single quote (') characters."
"103","Time","Async wait","Test order dependency","","","","**JIRA**: [JBPM-9895](https://issues.redhat.com/browse/JBPM-9895)    Cherry-pick from adc8aaf884bb967b2d25bb0072b4063b3ddcdf96"
"112","Concurrency","Async wait","Async wait","","","","I moved this in a previous PR, but I think firstly it's only actually required by one of the tests, and more importantly it might be reloading the object before the page has finished submitting."
"114","Concurrency","Async wait","Time","","","","6.0.0    Release version:    ## Summary    Fix some flaky tests found on master:    - persistence_enabled.mqttv5.t_takeover_clean_session_with_delayed_willmsg  - emqx_prometheus_data_SUITE      ## PR Checklist  <!--  Please convert the PR to a draft if any of the following conditions are not met.  -->  - [ ] For internal contributor: there is a jira ticket to track this change  - [x] The changes are covered with new or existing tests  - [ ] n/a Change log for changes visible by users has been added to `changes/ee/(feat|perf|fix|breaking)-<PR-id>.en.md` files  - [x] Schema changes are backward compatible or intentionally breaking (describe the changes and the reasoning in the summary)    <!--  Please, take in account the following guidelines while working on PR:  * Try to achieve reasonable coverage of the new code  * Add property-based tests for code that performs complex user input validation or implements a complex algorithm  * Create a PR to [emqx-docs](https://github.com/emqx/emqx-docs) if documentation update is required, or make a follow-up jira ticket  * Do not squash large PRs into a single commit, try to keep comprehensive history of incremental changes  * Do not squash any significant amount of review fixes into the previous commits  -->    <!--  ## Checklist for CI (.github/workflows) changes  - [ ] If changed package build workflow, pass [this action](https://github.com/emqx/emqx/actions/workflows/build_packages.yaml) (manual trigger)  - [ ] Change log has been added to `changes/` dir for user-facing artifacts update  -->"
"115","Test order dependency","Time","Time","","","","In conn_test.go, ""TestStartupTimeout"" at the very last step requires the log to contain ""no response to connection startup within timeout"".    However, during my test, it fails sometimes, not always, with log containing ""no response received from cassandra within timeout period"" instead.    Fixing the flaky test by allowing log to contain either message."
"117","Concurrency","Async wait","Time","","","","Some tests may randomly fail du to debounce timer on field validation."
"118","Async wait","Async wait","Test order dependency","","","","The root cause was that `andIUnlinkTheDefendant` was navigating to the defendant details screen as part of its implementation. But it was only called after `andIClickThroughToTheDefendantDetailsScreen`, which _also_ navigates to the defendant details screen. For some reason most of the time playwright wasn't complaining about the double-click, but just occasionally, in Safari, it was. Keeping `andIUnlinkTheDefendant` to just filling out the unlink form fixes the flakiness."
"120","Network","Async wait","Network","","","","Currently, there's a clause that sends no response when the connection  staet in the channel is `idle`, the initial state.    https://github.com/emqx/emqx/blob/e861f3963e9eee6b16e685aa4c7b57ed428d041b/apps/emqx/src/emqx_channel.erl#L490    Here, we attempt to publish a simple message before sending the large  one to ensure that the channel's connection state is connected."
"121","Randomness","OS","OS","","","","[PR Linked Issue] <!-- ‚ö†Ô∏è‚ö†Ô∏è Do Not Delete This! bug_report_template ‚ö†Ô∏è‚ö†Ô∏è --> <!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ --> <!-- üïÆ Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions --> <!-- üîé Search existing issues to avoid creating duplicates. --> <!-- üß™ Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ --> <!-- üí° Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. --> <!-- üîß Launch with `code --disable-extensions` to check. --> Does this issue occur when all extensions are disabled?: Yes/No  <!-- ü™ì If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. --> <!-- üì£ Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. --> - VS Code Version:  - OS Version:   My PR is failing to be merged due to windows unit tests failing surrounding composite tokens  https://dev.azure.com/vscode/VSCode/_build/results?buildId=152385&view=logs&j=e4714b0f-e6ff-5e04-bac1-2dcbc509f151&t=5d351641-7442-59b2-8726-6d905a792029  ```   4442 passing (37s)   96 pending   1 failing    1) Composite***        ‚Ä¢ equals          ‚Ä¢ true            ‚Ä¢ composite tokens:      Error: Method not implemented.       at Test***.toString (file:///D:/a/_work/1/s/out/vs/editor/test/common/codecs/tokens/composite***.test.js:20:13)       at Base***.fullRange (file:///D:/a/_work/1/s/out/vs/editor/common/codecs/base***.js:87:54)       at new Composite*** (file:///D:/a/_work/1/s/out/vs/editor/common/codecs/composite***.js:4:21)       at new Test*** (file:///D:/a/_work/1/s/out/vs/editor/test/common/codecs/tokens/composite***.test.js:17:7)       at Context.<anonymous> (file:///D:/a/_work/1/s/out/vs/editor/test/common/codecs/tokens/composite***.test.js:126:24)       at process.processImmediate (node:internal/timers:483:21)  ```"
"122","Async wait","Async wait","Test order dependency","","","","<!-- Thank you for submitting a Pull Request. Please: * Read our Pull Request guidelines:   https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests * Associate an issue with the Pull Request. * Ensure that the code is up-to-date with the `main` branch. * Include a description of the proposed changes and how to test them. -->"
"123","I/O","Async wait","Async wait","","","","[PR Linked Issue]  1) VSCode Smoke Tests (Electron)         Terminal           Terminal Persistence             detach/attach               should persist buffer content:       Error: Timeout: get element '.quick-input-widget' after 20 seconds.        at Code.poll (/Users/runner/work/1/s/test/automation/out/code.js:204:23)        at async Code.waitForElement (/Users/runner/work/1/s/test/automation/out/code.js:163:16)        at async QuickInput.waitForQuickInputClosed (/Users/runner/work/1/s/test/automation/out/quickinput.js:32:9)        at async Terminal.runCommandWithValue (/Users/runner/work/1/s/test/automation/out/terminal.js:109:9)        at async Context.<anonymous> (out/areas/terminal/terminal-persistence.test.js:64:17)    https://dev.azure.com/monacotools/Monaco/_build/results?buildId=278997&view=logs&j=260a512b-e5ca-5cf1-3f8e-20c0fa41efc9&t=dc7a7a05-ae89-521b-55db-0cb2ded34668"
"124","Randomness","Async wait","Test order dependency","","","","Terminal Extension pty terminals should respect dimension overrides    Fixes #90064"
"125","I/O","OS","Test order dependency","","","","## Description    This PR addresses the issue of flaky test results when executing the `run` command test (`verifies that a melos script can call another script containing steps, and ensures all commands in those steps are executed successfully`) in Linux CI/CD environments, as reported in issue #670.     Closes #670    ## Type of Change    <!--- Put an `x` in all the boxes that apply: -->    - [ ] ‚ú® `feat` -- New feature (non-breaking change which adds functionality)  - [x] üõ†Ô∏è `fix` -- Bug fix (non-breaking change which fixes an issue)  - [ ] ‚ùå `!` -- Breaking change (fix or feature that would cause existing functionality to change)  - [ ] üßπ `refactor` -- Code refactor  - [ ] ‚úÖ `ci` -- Build configuration change  - [ ] üìù `docs` -- Documentation  - [ ] üóëÔ∏è `chore` -- Chore"
"126","I/O","Async wait","Test order dependency","","","","fixes #36695"
"127","Concurrency","Unordered collections","Unordered collections","","","","The test `Win32ProgramRepositoryMustCallOnAppRenamedForLnkAppsWhenRenamedEventIsRaised` was experiencing random failures due to object identity mismatches in the repository's hash-based storage system.    ## Root Cause    The test was manually creating `Win32Program` objects:    ```csharp  Win32Program olditem = new Win32Program  {      Name = ""oldpath"",      ExecutableName = oldpath,      FullPath = linkingTo,  };  ```    However, the `DoOnAppRenamedAsync` method creates the `oldApp` object for removal using a different approach for .lnk files:    ```csharp  oldApp = new Win32Program() {       Name = Path.GetFileNameWithoutExtension(e.OldName),       ExecutableName = Path.GetFileName(e.OldName),       FullPath = newApp?.FullPath ?? oldPath   };  ```    Since the repository uses `GetHashCode()` (based on `Name`, `ExecutableName`, and `FullPath`) to identify objects for removal, any subtle differences in these properties would cause the `Remove()` operation to fail, leading to test assertion failures.    ## Fix    Changed the test to use `Win32Program.GetAppFromPath()` instead of manual object creation:    ```csharp  Win32Program olditem = Win32Program.GetAppFromPath(oldFullPath);  Win32Program newitem = Win32Program.GetAppFromPath(newFullPath);  ```    This mirrors the approach used in the working `Win32ProgramRepositoryMustCallOnAppRenamedForUrlAppsWhenRenamedEventIsRaised` test and ensures that test objects are created using the same code path as the production code, eliminating hash code mismatches.    ## Why This Was Random    The test failure appeared random because it depended on subtle differences in object creation that could vary based on timing, mock setup, or other environmental factors. By using the same object creation method as the production code, the test becomes deterministic."
"128","Concurrency","Async wait","Time","","","","<!-- Enter a brief description/summary of your PR here. What does it fix/what does it change/how was it tested (even manually, if necessary)? -->  ## Summary of the Pull Request    Sometimes the Interop Tests hung in CI. This seems to be caused by the sending of a message before the OS has set up the pipes correctly. We add a little wait to the test to reduce flakiness.    <!-- Describe how you validated the behavior. Add automated tests wherever possible, but list manual validation steps taken as well -->  ## Validation Steps Performed  ![image](https://github.com/microsoft/PowerToys/assets/26118718/fa326de5-89fa-411a-b678-e36878c6cbb6)  Ran the ""TestSend"" with ""Run Until Failure"" and it ran 1000 times without hanging."
"129","Async wait","Async wait","Network","","","","<!-- Enter a brief description/summary of your PR here. What does it fix/what does it change/how was it tested (even manually, if necessary)? -->  ## Summary of the Pull Request    Another attempt for trying to fix flaky WebView2 CI ü§û     <!-- Please review the items on the PR checklist before submitting-->  ## PR Checklist    - [ ] **Closes:** #xxx  - [ ] **Communication:** I've discussed this with core contributors already. If work hasn't been agreed, this work might be rejected  - [ ] **Tests:** Added/updated and all pass  - [ ] **Localization:** All end user facing strings can be localized  - [ ] **Dev docs:** Added/updated  - [ ] **New binaries:** Added on the required places     - [ ] [JSON for signing](https://github.com/microsoft/PowerToys/blob/main/.pipelines/ESRPSigning_core.json) for new binaries     - [ ] [WXS for installer](https://github.com/microsoft/PowerToys/blob/main/installer/PowerToysSetup/Product.wxs) for new binaries and localization folder     - [ ] [YML for CI pipeline](https://github.com/microsoft/PowerToys/blob/main/.pipelines/ci/templates/build-powertoys-steps.yml) for new test projects     - [ ] [YML for signed pipeline](https://github.com/microsoft/PowerToys/blob/main/.pipelines/release.yml)  - [ ] **Documentation updated:** If checked, please file a pull request on [our docs repo](https://github.com/MicrosoftDocs/windows-uwp/tree/docs/hub/powertoys) and link it here: #xxx    <!-- Provide a more detailed description of the PR, other things fixed or any additional comments/features here -->  ## Detailed Description of the Pull Request / Additional comments    <!-- Describe how you validated the behavior. Add automated tests wherever possible, but list manual validation steps taken as well -->  ## Validation Steps Performed"
"130","I/O","Time","Time","","","","## Summary of the Pull Request  This might be the problem why from time to time `MarkdownPreviewHandlerControlAddsBrowserToFormWhenDoPreviewIsCalled ` test fails - timeouts after 10s    **What is this about:**    **What is included in the PR:**     **How does someone test / validate:**     ## Quality Checklist    - [ ] **Linked issue:** #xxx  - [ ] **Communication:** I've discussed this with core contributors in the issue.   - [ ] **Tests:** Added/updated and all pass  - [ ] **Installer:** Added/updated and all pass  - [ ] **Localization:** All end user facing strings can be localized  - [ ] **Docs:** Added/ updated  - [ ] **Binaries:** Any new files are added to WXS / YML     - [ ] No new binaries     - [ ] [YML for signing](https://github.com/microsoft/PowerToys/blob/main/.pipelines/pipeline.user.windows.yml#L68) for new binaries     - [ ] [WXS for installer](https://github.com/microsoft/PowerToys/blob/main/installer/PowerToysSetup/Product.wxs) for new binaries    ## Contributor License Agreement (CLA)  A CLA must be signed. If not, go over [here](https://cla.opensource.microsoft.com/microsoft/PowerToys) and sign the CLA."
"134","Concurrency","Concurrency","Async wait","","","","### What changes were proposed in this pull request?    Simplify org.apache.spark.sql.connect.execution.ReattachableExecuteSuite.""reattach after connection expired"" to make it more deterministic.    ### Why are the changes needed?    The test previously involved execution and interruption that made the test unnecessarily flaky, e.g., an exception was thrown when releasing the corresponding [execution](https://github.com/apache/spark/actions/runs/12296721038/job/34316344940), not when reattaching the execution.  - The test's sole purpose is to check whether the lack of 'session' results in the correct error code.  - The involvement of actual query execution only makes the test flaky and complicated.    ### Does this PR introduce _any_ user-facing change?    No.    ### How was this patch tested?    Repeatedly ran testOnly org.apache.spark.sql.connect.execution.ReattachableExecuteSuite.    ### Was this patch authored or co-authored using generative AI tooling?    No."
"135","Async wait","Time","Time","","","","### What changes were proposed in this pull request?  This PR increases the max time we wait for a connect server to come up for testing. The current threshold is too low, and is causing flakyness.    ### Why are the changes needed?  It makes connect tests less flaky.    ### Does this PR introduce _any_ user-facing change?  No.    ### How was this patch tested?  It is test infra code.    ### Was this patch authored or co-authored using generative AI tooling?  No."
"152","Unordered collections","I/O","Test order dependency","","","","The problem is that in the yoga example's training data there are 5 classes but when using any other amount of classes as training data the training fails. Set the output layer to the actual number of classes instead.    Without this fix, a ValueError is raised (e.g. `ValueError: Shapes (None, 7) and (None, 5) are incompatible`)."
"153","Time","Async wait","Resource leak","","","","**What type of PR is this?**    /kind bug    **What this PR does / why we need it**:    Pod with PVC will not be scheduled if the PVC is being deleted.  This can happen when the PVC has finalizers of storage plugins.    Such a pod becomes pending.  Unfortunately, after the finalizer  finishes and PVC is deleted, the pod remains pending forever.  The StatefulSet controller does nothing for this pending pod.    This commit prevents the StatefulSet controller from creating  such pods when PVC is to be deleted.    Reprocedure:    1. Create a single node cluster with [kind](https://github.com/kubernetes-sigs/kind).  2. Create a StatefulSet with the following manifests:    ```yaml  apiVersion: v1  kind: Service  metadata:    name: test    namespace: default  spec:    clusterIP: None    selector:      app: test  ---  apiVersion: apps/v1  kind: StatefulSet  metadata:    name: test    namespace: default  spec:    replicas: 1    selector:      matchLabels:        app: test    serviceName: test    template:      metadata:        labels:          app: test      spec:        containers:        - command:          - pause          image: quay.io/cybozu/ubuntu:18.04          name: ubuntu          volumeMounts:          - mountPath: /usr/share/nginx/html            name: www    volumeClaimTemplates:    - metadata:        name: www      spec:        accessModes:        - ReadWriteOnce        resources:          requests:            storage: 1Gi        volumeMode: Filesystem  ```    3. Once the pod gets running, edit PVC to add a finalizer `aaa.bbb/ccc`.  4. Run `kubectl delete --wait=false pvc/www-test-0`.  5. Run `kubectl delete --wait=false pods/test-0`.  6. See a new pod is created and become pending.  7. Edit the PVC to remove the `aaa.bbb/ccc` finalizer.  8. See the PVC is get deleted.  9. See the Pod remains pending forever.    **Does this PR introduce a user-facing change?**:  ```release-note  Adding fix to statefulset controller to wait for pvc deletion before creating pods.  ```"
"157","Unordered collections","Async wait","Network","","","","https://github.com/emqx/emqx/actions/runs/17472259934/job/49624282534?pr=15846#step:4:381"
"159","Resource leak","Concurrency","Randomness","","","","Fixes random failures in the killSkipmeYesNo test by asserting that at least one client is killed, instead of exactly one.    Closes #4165"
"160","Async wait","Async wait","Time","","","","The test JedisPoolTest.testCloseConnectionOnMakeObject occasionally fails with the following error:        `JedisPoolTest.testCloseConnectionOnMakeObject:403 expected:<4> but was:<5>`    **Root Cause:**  The assertion is based on the output of getClientCount(jedis.clientList()), which is called immediately after closing a connection. However, Redis may take a short time to remove the closed connection from the client list, leading to a transient count mismatch and a flaky test result.    **Example stack trace:**  ```  Error:  redis.clients.jedis.JedisPoolTest.testCloseConnectionOnMakeObject -- Time elapsed: 0.006 s <<< FAILURE!  java.lang.AssertionError: expected:<4> but was:<5>  	at org.junit.Assert.fail(Assert.java:89)  	at org.junit.Assert.failNotEquals(Assert.java:835)  	at org.junit.Assert.assertEquals(Assert.java:647)  	at org.junit.Assert.assertEquals(Assert.java:633)  	at redis.clients.jedis.JedisPoolTest.testCloseConnectionOnMakeObject(JedisPoolTest.java:403)  ```  	  closes #4135"
"165","Randomness","Unordered collections","Test order dependency","","","","The test `test_installed_modules` appears to not be all that useful.  The test exists to verify the behavior of the [`_generate_installed_modules` function](https://github.com/getsentry/sentry-python/blob/9b66f3b51502ca600554c711bc3f599c18f8f18b/sentry_sdk/utils.py#L1689). However, all the test does is essentially check the output of `_generate_installed_modules` against a refactored version of the function call itself.  In short, in its current form, the test appears to not make too much sense. As the test recently started failing, let's just delete it.  <!-- Describe your PR here -->  ---  Thank you for contributing to `sentry-python`! Please add tests to validate your changes, and lint your code using `tox -e linters`.  Running the test suite on your PR might require maintainer approval."
"166","OS","Time","OS","","","","There's a test in `test_utils.py` that flakes very often, but only on Python 3.8 and only in CI (locally it's all fine). I've tried a couple of ways to fix it but at this point it's not worth the effort, so just skipping it on 3.8."
"178","Concurrency","Time","Test order dependency","","","","Fixes #13547"
"186","Resource leak","Test order dependency","Network","","","","‚Ä¶ot specifying topic"
"187","Async wait","Concurrency","Network","","","","<!--  !!!ATTENTION!!!    If you are fixing *any* crash or *any* potential security issue, *do not*  open a pull request in this repo. Please report the issue via emailing  envoy-security@googlegroups.com where the issue will be triaged appropriately.  Thank you in advance for helping to keep Envoy secure.    !!!ATTENTION!!!    For an explanation of how to fill out the fields, please see the relevant section  in [PULL_REQUESTS.md](https://github.com/envoyproxy/envoy/blob/main/PULL_REQUESTS.md)  -->    Fix #29595     It is possible that we will get data + rst from the wrapped transport socket since there is a `do {} while` loop. We should trigger the `onRead` if there is any processed data.    Do not flake anymore.  ```  bazel test test/integration:protocol_integration_test --test_filter=""*LargeRequestMethod*"" --test_arg=""-l trace"" -c opt --runs_per_test=1000  ```    Commit Message:  Additional Description:  Risk Level:  Testing:  Docs Changes:  Release Notes:  Platform Specific Features:  [Optional Runtime guard:]  [Optional Fixes #Issue]  [Optional Fixes commit #PR or SHA]  [Optional Deprecated:]  [Optional [API Considerations](https://github.com/envoyproxy/envoy/blob/main/api/review_checklist.md):]"
"189","Resource leak","Concurrency","Network","","","","<!--  !!!ATTENTION!!!    If you are fixing *any* crash or *any* potential security issue, *do not*  open a pull request in this repo. Please report the issue via emailing  envoy-security@googlegroups.com where the issue will be triaged appropriately.  Thank you in advance for helping to keep Envoy secure.    !!!ATTENTION!!!    For an explanation of how to fill out the fields, please see the relevant section  in [PULL_REQUESTS.md](https://github.com/envoyproxy/envoy/blob/main/PULL_REQUESTS.md)  -->    Commit Message: aws: fix test flake when no IMDS can be found  Additional Description: Lack of IMDS (169.254.169.254 address) can cause a race condition and crash during testing due to the shutdown of cluster manager. This scenario should not occur normally, as cluster manager will still exist and the lack of IMDS is handled gracefully.  Risk Level: Low  Testing: N/A  Docs Changes:  Release Notes:  Platform Specific Features:  [Optional Runtime guard:]  [Optional Fixes #Issue]  [Optional Fixes commit #PR or SHA]  [Optional Deprecated:]  [Optional [API Considerations](https://github.com/envoyproxy/envoy/blob/main/api/review_checklist.md):]"
"190","Async wait","Async wait","Time","","","","[PR Linked Issue] Few of recent ci runs have failures for `//test/extensions/filters/http/alternate_protocols_cache:filter_integration_test`: https://github.com/envoyproxy/envoy/actions/runs/15444829526/job/43471494796 https://github.com/envoyproxy/envoy/actions/runs/15439887326/job/43454992923 ci log: ``` [ RUN      ] Protocols/MixedUpstreamIntegrationTest.BasicRequestAutoWithHttp3/IPv4_Http2Downstream_Http3UpstreamHttpParserNghttp2Legacy test/extensions/filters/http/alternate_protocols_cache/filter_integration_test.cc:536: Failure Expected: (getSrtt(alt_svc, timeSystem())) != (0), actual: 0 vs 0 Alt-svc entry :'' Stack trace:   0xaaaad262aa0c: Envoy::(anonymous namespace)::MixedUpstreamIntegrationTest_BasicRequestAutoWithHttp3_Test::TestBody()   0xaaaad3ad4224: testing::internal::HandleExceptionsInMethodIfSupported<>()   0xaaaad3ad40c0: testing::Test::Run()   0xaaaad3ad528c: testing::TestInfo::Run() ... Google Test internal frames ...  [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_quic_always_support_server_preferred_address to: true [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_reloadable_features_enable_universal_header_validator to: false [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_reloadable_features_http1_use_balsa_parser to: true [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_reloadable_features_http2_use_oghttp2 to: true [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_reloadable_features_no_extension_lookup_by_name to: true [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_reloadable_features_runtime_initialized to: false [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_quic_always_support_server_preferred_address to: true [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_reloadable_features_enable_universal_header_validator to: false [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_reloadable_features_http1_use_balsa_parser to: true [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_reloadable_features_http2_use_oghttp2 to: true [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_reloadable_features_no_extension_lookup_by_name to: true [external/com_google_absl/absl/flags/internal/flag.cc : 147] RAW: Restore saved value of envoy_reloadable_features_runtime_initialized to: false [  FAILED  ] Protocols/MixedUpstreamIntegrationTest.BasicRequestAutoWithHttp3/IPv4_Http2Downstream_Http3UpstreamHttpParserNghttp2Legacy, where GetParam() = 24-byte object <00-00 00-00 01-00 00-00 02-00 00-00 00-00 00-00 00-00 00-00 00-00 00-00> (571 ms) ```"
"191","Async wait","Resource leak","Resource leak","","","","[PR Linked Issue] https://circleci.com/gh/square/okhttp/8330?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link    closeReasonMaximumLength - okhttp3.internal.ws.WebSocketHttpTest  ```  org.junit.ComparisonFailure: expected:<[0]> but was:<[1]>  	at okhttp3.OkHttpClientTestRule.ensureAllConnectionsReleased(OkHttpClientTestRule.kt:91)  	at okhttp3.OkHttpClientTestRule$apply$1.evaluate(OkHttpClientTestRule.kt:121)  ```    serverCloseThenClientClose - okhttp3.internal.ws.RealWebSocketTest  ```  java.lang.AssertionError:   Expecting empty but was:<[Closed[1000 Hello!]]>  	at okhttp3.internal.ws.WebSocketRecorder.assertExhausted(WebSocketRecorder.java:163)  	at okhttp3.internal.ws.RealWebSocketTest.tearDown(RealWebSocketTest.java:58)  ```"
"192","Concurrency","Async wait","Async wait","","","","[PR Linked Issue] https://github.com/square/okhttp/actions/runs/7593827185/job/20684688664      ```  HttpOverHttp2Test > concurrentRequestWithEmptyFlowControlWindow(Protocol, MockWebServer) > [1] h2_prior_knowledge FAILED      java.lang.AssertionError: Timed out waiting for log message.          at okhttp3.TestLogHandler.take(TestLogHandler.kt:92)          at okhttp3.internal.http2.HttpOverHttp2Test.waitForDataFrames(HttpOverHttp2Test.kt:425)          at okhttp3.internal.http2.HttpOverHttp2Test.concurrentRequestWithEmptyFlowControlWindow(HttpOverHttp2Test.kt:481)  ```            Steps   1. FakeFileSystem cache to remove that issue  2. Close requests cleanly  3. Verify in CI"
"194","Test order dependency","Concurrency","Concurrency","","","","These tests were causing flakes where the mock method was being called more than once. The tests were also difficult to understand.  This change removes the need for mocking (hopefully increasing test stability) and also should hopefully make it easier to understand what these tests are meant to be checking"
"198","OS","I/O","Concurrency","","","","Ideas and help of Alexander Motin ;)    Ticket: #28198  (cherry picked from commit ef3eb51d9b80715c45401827316ab1ef7fc6933b)"
"200","I/O","Time","Randomness","","","","[PR Linked Issue] $1K per flakey test"
"201","Network","Async wait","Resource leak","","","","### Description  This is a PR for SEISMIC. I found there would be flakey tests within previous `warmUp` and `clearCache` related ITs. I fixed them in this PR. In addition, I refactored some codes to be cleaner.    ### Related Issues  Previous IT: #1559     ### Check List  - [ ] New functionality includes testing.  - [ ] New functionality has been documented.  - [ ] API changes companion pull request [created](https://github.com/opensearch-project/opensearch-api-specification/blob/main/DEVELOPER_GUIDE.md).  - [x] Commits are signed per the DCO using `--signoff`.  - [x] Public documentation issue/PR [created](https://github.com/opensearch-project/documentation-website/issues/new/choose).    By submitting this pull request, I confirm that my contribution is made under the terms of the Apache 2.0 license.  For more information on following Developer Certificate of Origin and signing off your commits, please check [here](https://github.com/opensearch-project/neural-search/blob/main/CONTRIBUTING.md#developer-certificate-of-origin)."
"202","Async wait","Network","Network","","","","The `getContext` seem to randomly timing out on github action.   <img width=""494"" alt=""image"" src=""https://github.com/radarlabs/radar-sdk-ios/assets/139801512/9de1176f-0d6b-434e-b63a-f28b242da8e2"">  <img width=""417"" alt=""image"" src=""https://github.com/radarlabs/radar-sdk-ios/assets/139801512/ec3ec059-f3cc-47aa-8f3f-54ac4a7e72ad"">  This is likely an issue with github action because  - This does not occur on circle CI  - This does not occur on local testing  As a sanity check, the SDK endpoint for `getContext` was called on waypoint with no noticeable issue."
"203","Test order dependency","Test order dependency","Resource leak","","","","trust center tests need to create their own users because of top level restrictions on number of trust centers"
"204","Async wait","Async wait","Network","","","","When you have a rewrite in middleware like this:  ```ts  return NextResponse.rewrite(u, {    status: 403,  });  ```  The rewrite status code is not propogated to the cache interceptor's responses when you have an external middleware.     We can also safely remove the `x-next-cache-tags` header on the response.    I did update some tests that were flakey aswell. We need to register the event listener before the navigation."
"206","Time","Network","Network","","","","Fixes #145 -  the issue was caused by the slightly variable results returned by the GitHub API.    In all the tests in `FunctionalSpec`, we create several test fixtures with the GitHub API, each created to be used once and thrown away:    * A brand-new GitHub repository, populated with whatever Git history we require  * A brand new PR in the repository, which we also merge    Before continuing on to the next step, which would be having Prout scan the repo for recently-merged PRs, we perform several checks to ensure that the GitHub API confirms the status of the merged PR:    https://github.com/guardian/prout/blob/a710e347afb94ca719e11b9c5b6b3312f1245e98/test/lib/Helpers.scala#L180-L195    However, looking a the differing logs produced by the failure & success cases in #145, it became apparent that even though we've checked the GitHub API."
"210","Test order dependency","Test order dependency","Network","","","","‚Ä¶ot specifying topic"
"212","Test order dependency","Async wait","Time","","","","Fixes #2495: **Kubelet doesn't kill old pods when BoundPods is empty**  The first time kubelet starts, while there are no updates, `kl.pods` is `nil` ([pkg/kubelet/kubelet.go#L1118](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/pkg/kubelet/kubelet.go#L1118)):  ``` GO case <-time.After(kl.resyncInterval):     glog.V(4).Infof(""Periodic sync"")     if kl.pods == nil {         continue     } ```  which guarantees that [`syncPods(...)`](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/pkg/kubelet/kubelet.go#L992), which contains the container killing logic is never called.  So the first part of the fix is to remove this check and allow `syncPods(...)` to be called even when nil, so that the first periodic sync can clean up old containers.  However, this isn't enough because inside `syncPods(...)` there is a check to make sure that all sources have been ""seen"" before it will kill old containers ([pkg/kubelet/kubelet.go#L1026](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/pkg/kubelet/kubelet.go#L1026)):  ``` GO if !kl.sourcesReady() {     // If the sources aren't ready, skip deletion, as we may accidentally delete pods     // for sources that haven't reported yet.     glog.V(4).Infof(""Skipping deletes, sources aren't ready yet."")     return nil } ```  This check is performed in the [`SeenAllSources()`](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/pkg/kubelet/config/config.go#L87) function, and is `true` only if a `SET` update has been seen for all registered kubelet sources.  However, no `SET` update is emitted by any of the sources until they successfully read a value, which means the original problem still exists.  So the second part of the fix is to have the kubelet boundpod sources (etcd, file, and http) all emit a `SET` update with an empty pod list when the source is first read but no value exists; the empty update will not make it back to the kubelet sync loop because it will be filtered out by the [update merge logic](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/pkg/kubelet/config/config.go#L140); but it will cause the source to be [marked as seen](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/pkg/kubelet/config/config.go#L238) so the periodic sync (enabled by the first fix) will clean up the old containers (since all sources will now be marked as seen after the first read attempt)."
"223","Async wait","Test order dependency","Test order dependency","","","","Thanks for Diana Carroll to report this issue (https://spark-project.atlassian.net/browse/SPARK-1100)  the current saveAsTextFile/SequenceFile will overwrite the output directory silently if the directory already exists, this behaviour is not desirable because  overwriting the data silently is not user-friendly  if the partition number of two writing operation changed, then the output directory will contain the results generated by two runnings  My fix includes:  add some new APIs with a flag for users to define whether he/she wants to overwrite the directory: if the flag is set to true, then the output directory is deleted first and then written into the new data to prevent the output directory contains results from multiple rounds of running;  if the flag is set to false, Spark will throw an exception if the output directory already exists  changed JavaAPI part  default behaviour is overwriting  Two questions  should we deprecate the old APIs without such a flag?  I noticed that Spark Streaming also called these APIs, I thought we don't need to change the related part in streaming? @tdas"
"225","Async wait","Test order dependency","I/O","","","","Previously, ZooKeeperPersistenceEngine would crash the whole Master process if there was stored data from a prior Spark version. Now, we just delete these files."
"228","Time","Unordered collections","Test order dependency","","","","I have written integration code which would allow conditionExpressions to be xpath and evaluator for it  also test case is added to illustrate the use of xpath"
"229","Async wait","I/O","Network","","","","Also change cloudcfg.sh, to make it possible to call from the examples/guestbook directory."
"231","Time","OS","OS","","","","<!--  Thanks for sending a pull request!  Here are some tips for you:  1. If this is your first time, read our contributor guidelines https://git.k8s.io/community/contributors/devel/pull-requests.md#the-pr-submit-process and developer guide https://git.k8s.io/community/contributors/devel/development.md#development-guide  2. If you want *faster* PR reviews, read how: https://git.k8s.io/community/contributors/devel/pull-requests.md#best-practices-for-faster-reviews  3. Follow the instructions for writing a release note: https://git.k8s.io/community/contributors/devel/pull-requests.md#write-release-notes-if-needed  -->    **What this PR does / why we need it**:  Delete ""hugetlb"" from whitelistControllers    **Which issue this PR fixes** *(optional, in `fixes #<issue number>(, fixes #<issue_number>, ...)` format, will close that issue when PR gets merged)*: fixes #50770    **Special notes for your reviewer**:    **Release note**:  <!--  Steps to write your release note:  1. Use the release-note-* labels to set the release note state (if you have access)  2. Enter your extended release note in the below block; leaving it blank means using the PR title as the release note. If no release note is required, just write `NONE`.  -->  ```  NONE  ```"
"233","Test order dependency","Resource leak","Resource leak","","","","Stack from [ghstack](https://github.com/ezyang/ghstack) (oldest at bottom):  * __->__ #159443    under dynamo, the libraries couldn't properly be cleared unless we manually did `gc.collect()`, but that's slow. it also worked if we just used the _destroy() method to tear down     FIXES   #159398  #159349  #159254  #159237  #159153  #159114  #159040  #158910  #158841  #158763  #158735  cc @voznesenskym @penguinwu @EikanWang @jgong5 @Guobing-Chen @XiaobingSuper @zhuhaozhe @blzheng @wenzhe-nrv @jiayisunx @chenyang78 @kadeng @chauhang @amjames @Lucaskabela"
"235","Test order dependency","Resource leak","Resource leak","","","","[PR Linked Issue] Fixing existing runs:  - [x] Don't run Jedi on PyPy. (see https://github.com/python-trio/trio/pull/2887 and https://github.com/python-trio/trio/pull/3075) (need to update `test_static_tool_sees_class_members` too)  - [x] Only run autodeps in `python-trio/trio` (see https://github.com/python-trio/trio/pull/2892)  - [x] Add a `gc.collect()` to the top of `test_for_leaking_fds` (this seems to address test flakiness I've seen elsewhere) (see https://github.com/python-trio/trio/pull/2888)  - [x] Start running `mypy` on PyPy. (see https://github.com/python-trio/trio/pull/3075)  - [x] switch macos to run on m1 (see https://github.com/python-trio/trio/pull/2953)    Adding more runs:  - [ ] Add an anaconda run  - [x] Alpine run (see https://github.com/python-trio/trio/pull/2933)  - [ ] Try out qemu for a freebsd  - [x] Cython run (see https://github.com/python-trio/trio/pull/2942)    - [ ] Run full test suite on Cython  - [x] Update MacOS and Windows Python matrix to support 3.11 and 3.12. (see https://github.com/python-trio/trio/pull/3017)  - [x] Add CPython 3.13 (see https://github.com/python-trio/trio/pull/3005)  - [ ] ... Android run??? (https://github.com/marketplace/actions/android-emulator-runner ??)  - [x] pypy nightly 3.11 (not possible)  - [x] add pypy runs for macos (see https://github.com/python-trio/trio/pull/3074)  - [x] add pypy runs for windows (see #2776 and #2678) (see https://github.com/python-trio/trio/pull/3074)    Removing runs:  - [x] Don't run PyPy nightlies less than 3.11 (see https://github.com/python-trio/trio/pull/2952)    These feel like they will take more motivation than I currently have :("
"238","Concurrency","Network","OS","","","","[PR Linked Issue] CI test **darwin://python/ray/tests:test_multi_node** is consistently_failing. Recent failures:  	- https://buildkite.com/ray-project/postmerge-macos/builds/7162#01987fcf-d2dd-40d7-ab47-675bc7df8452 	- https://buildkite.com/ray-project/postmerge-macos/builds/7162#01987f0b-3872-4031-a057-406c38641c46  DataCaseName-darwin://python/ray/tests:test_multi_node-END Managed by OSS Test Policy"
"242","Concurrency","Async wait","Async wait","","","","Summary: The test has been [flaky](https://github.com/facebook/rocksdb/actions/runs/12220443012/job/34088263578?fbclid=IwZXh0bgNhZW0CMTEAAR3iDUK20Z4kdFkYZOT_PgQMYuj3Ebmpf4O-OOLLyeFQs4HAb8pRTWpFnUo_aem_09A_yiv7cwoD5lKjxFKimA). The cause for flakiness is that background threads may not be immediately available after calling env_->SetBackgroundThreads() while the test expects all background threads to be available for compaction. There's no way to get the number of available threads and I don't want to update threadpool implementation just for this test. So I added a fix to wait until background threads being available that relies on sync point.       Test plan: monitor future test failure"
"243","Async wait","Time","Time","","","","Refs #943    * We've already got a test that ensures `response.elapsed > datetime.timedelta(0)`, so let's not try to enforce a ""this should end up as more than one second"" case.  * Let's bump the slow response default to a more reliably noticable 1 second delay."
"244","Floating point operations","Resource leak","Test order dependency","","","","After https://github.com/python-pillow/Pillow/actions/runs/4256800436/jobs/7406140055, this is a further PR for #6875"
"245","Async wait","Time","Time","","","","### Feature or Bugfix  - Workaround    ### Purpose  - Reduce distration due to failed continuous integration pipelines.    ### Detail  - Increase the timeout duration in `linkcheck`-related test roots by a factor of 5x, to a quarter-second.    ### Relates  - May resolve #12159."
"246","Time","Async wait","Async wait","","","","As a follow-up to HDFS-16935, we should provide utility to trigger heartbeat and wait until BP thread queue is fully processed. This would ensure 100% consistency w.r.t active namenode being able to receive bad block reports from the given datanode. This utility would resolve flakes for the tests that rely on namenode's awareness of the reported bad blocks by datanodes."
"247","Time","Async wait","Time","","","","### Description of PR  testDecommissionStatus keeps failing intermittently.  ```  [ERROR] testDecommissionStatus(org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor)  Time elapsed: 3.299 s  <<< FAILURE!  java.lang.AssertionError: Unexpected num under-replicated blocks expected:<4> but was:<3>  	at org.junit.Assert.fail(Assert.java:89)  	at org.junit.Assert.failNotEquals(Assert.java:835)  	at org.junit.Assert.assertEquals(Assert.java:647)  	at org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.checkDecommissionStatus(TestDecommissioningStatus.java:169)  	at org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor.testDecommissionStatus(TestDecommissioningStatusWithBackoffMonitor.java:136)  ```    ### How was this patch tested?  Local run of unit test    ### For code changes:    - [X] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?"
"248","Time","Async wait","Network","","","","<!--    Thanks for sending a pull request!      1. If this is your first time, please read our contributor guidelines: https://cwiki.apache.org/confluence/display/HADOOP/How+To+Contribute      2. Make sure your PR title starts with JIRA issue id, e.g., 'HADOOP-17799. Your PR title ...'.  -->    ### Description of PR  Please refer to YARN-11816 for details.    ### How was this patch tested?      ### For code changes:    - [x] Does the title or this PR starts with the corresponding JIRA issue id (e.g. 'HADOOP-17799. Your PR title ...')?  - [ ] Object storage: have the integration tests been executed and the endpoint declared according to the connector-specific documentation?  - [ ] If adding new dependencies to the code, are these dependencies licensed in a way that is compatible for inclusion under [ASF 2.0](http://www.apache.org/legal/resolved.html#category-a)?  - [ ] If applicable, have you updated the `LICENSE`, `LICENSE-binary`, `NOTICE-binary` files?"
"250","Test order dependency","Resource leak","Resource leak","","","","Properly shutdown broker for each test and speed up tests by sending less messages"
"252","Async wait","Time","Time","","","","My theory is that since 0ebea6e5c07485a36862e9b6e2be18d1694ad2c5, the saving of objects has become slightly slower  This caused some failures in the selenium test suite: https://github.com/django/django/actions/runs/13826117388/job/38698352291"
"253","Unordered collections","Time","Test order dependency","","","","ticket-23842"
"254","OS","OS","Resource leak","","","","Noticed `test_basic_series_frame_alignment` and `test_raw_roundtrip` can occasitionally fail in the CI. Marking as xfail strict=False and clearing the clipboard respectively"
"255","OS","Network","Test order dependency","","","","- [x] [Tests added and passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#writing-tests) if fixing a bug or adding a new feature  - [x] All [code checks passed](https://pandas.pydata.org/pandas-docs/dev/development/contributing_codebase.html#pre-commit).    Example: https://app.circleci.com/pipelines/github/pandas-dev/pandas/8766/workflows/4a9ce4f4-0e1c-49aa-b035-ffcb6334be45/jobs/39610"
"260","Async wait","Async wait","Test order dependency","","","","For example this test fails randomly and needs to be re-run multiple times: https://github.com/mastra-ai/mastra/actions/runs/15888293944/job/44806477266?pr=5482    Seems to be flawed test logic (fixed here)"
"262","Test order dependency","Async wait","Network","","","","This PR sets up the sidebar and sidebar links    <img width=""1576"" alt=""Screenshot 2024-08-12 at 15 08 01"" src=""https://github.com/user-attachments/assets/4f732c78-c199-4ce8-b4a6-37b33e8287e9"">"
"268","Randomness","OS","Resource leak","","","","[PR Linked Issue] Really love this repo, I've been using it to finetune CodeGen models with >2k context windows.    It's way faster than hugging face (3x) and slightly faster than Megatron for the 350M and 2.7b parameter CodeGen models but doesn't work for the 6.1B and 16B parameter models as they have a head dimension of 256.    <img width=""1006"" alt=""Screen Shot 2022-11-01 at 5 32 47 PM"" src=""https://user-images.githubusercontent.com/17725268/199345886-f8b7531e-9918-4fba-ab37-4ae980ec2796.png"">    I would imagine CodeGen finetuning will be a solid use-case for flash attention since coding models can really benefit from long context windows. And CodeGen is basically SOTA for coding (competitive with Codex).    Is this something that is even possible with flash attention?"
"271","Async wait","OS","I/O","","","","Introduced by 3d707be950b387552585451071928e7b39cdfa53.    From docs buildbot: http://buildbot.python.org/all/builders/Docs%203.x/builds/399/steps/lint/logs/stdio    ```  python3 tools/rstlint.py -i tools -i venv  [1] faq/windows.rst:303: trailing whitespace  [1] faq/windows.rst:305: trailing whitespace  2 problems with severity 1 found.  ```"
"273","Test order dependency","Test order dependency","Resource leak","","","","Take 3: on win32 we use empty.txt in the fixtures directory, otherwise we use a file constructed specifically for this test due to POSIX socket path length limitations, in which case we need to do appropriate cleanup. Cleaning up empty.txt in fixtures causes downstream problems for other tests using it (currently the next test is test-zlib)."
"280","Async wait","Async wait","Test order dependency","","","","[PR Linked Issue] ### Failure cluster [46c1b1ee59dffad82fad](https://storage.googleapis.com/k8s-triage/index.html?pr=1#46c1b1ee59dffad82fad)    ##### Error text:  ```  === RUN   TestFrameworkHandler_IterateOverWaitingPods/pods_with_different_profiles_are_waiting_on_permit_stage      framework.go:381: I0229 10:48:13.714983] the scheduler starts to work with those plugins Plugins={""PreEnqueue"":{""Enabled"":null,""Disabled"":null},""QueueSort"":{""Enabled"":[{""Name"":""PrioritySort"",""Weight"":0}],""Disabled"":null},""PreFilter"":{""Enabled"":null,""Disabled"":null},""Filter"":{""Enabled"":null,""Disabled"":null},""PostFilter"":{""Enabled"":null,""Disabled"":null},""PreScore"":{""Enabled"":null,""Disabled"":null},""Score"":{""Enabled"":null,""Disabled"":null},""Reserve"":{""Enabled"":null,""Disabled"":null},""Permit"":{""Enabled"":[{""Name"":""fakePermit"",""Weight"":0}],""Disabled"":null},""PreBind"":{""Enabled"":null,""Disabled"":null},""Bind"":{""Enabled"":[{""Name"":""DefaultBinder"",""Weight"":0}],""Disabled"":null},""PostBind"":{""Enabled"":null,""Disabled"":null},""MultiPoint"":{""Enabled"":null,""Disabled"":null}}      framework.go:381: I0229 10:48:13.715309] the scheduler starts to work with those plugins Plugins={""PreEnqueue"":{""Enabled"":null,""Disabled"":null},""QueueSort"":{""Enabled"":[{""Name"":""PrioritySort"",""Weight"":0}],""Disabled"":null},""PreFilter"":{""Enabled"":null,""Disabled"":null},""Filter"":{""Enabled"":null,""Disabled"":null},""PostFilter"":{""Enabled"":null,""Disabled"":null},""PreScore"":{""Enabled"":null,""Disabled"":null},""Score"":{""Enabled"":null,""Disabled"":null},""Reserve"":{""Enabled"":null,""Disabled"":null},""Permit"":{""Enabled"":[{""Name"":""fakePermit"",""Weight"":0}],""Disabled"":null},""PreBind"":{""Enabled"":null,""Disabled"":null},""Bind"":{""Enabled"":[{""Name"":""DefaultBinder"",""Weight"":0}],""Disabled"":null},""PostBind"":{""Enabled"":null,""Disabled"":null},""MultiPoint"":{""Enabled"":null,""Disabled"":null}}      framework.go:381: I0229 10:48:13.715630] the scheduler starts to work with those plugins Plugins={""PreEnqueue"":{""Enabled"":null,""Disabled"":null},""QueueSort"":{""Enabled"":[{""Name"":""PrioritySort"",""Weight"":0}],""Disabled"":null},""PreFilter"":{""Enabled"":null,""Disabled"":null},""Filter"":{""Enabled"":null,""Disabled"":null},""PostFilter"":{""Enabled"":null,""Disabled"":null},""PreScore"":{""Enabled"":null,""Disabled"":null},""Score"":{""Enabled"":null,""Disabled"":null},""Reserve"":{""Enabled"":null,""Disabled"":null},""Permit"":{""Enabled"":[{""Name"":""fakePermit"",""Weight"":0}],""Disabled"":null},""PreBind"":{""Enabled"":null,""Disabled"":null},""Bind"":{""Enabled"":[{""Name"":""DefaultBinder"",""Weight"":0}],""Disabled"":null},""PostBind"":{""Enabled"":null,""Disabled"":null},""MultiPoint"":{""Enabled"":null,""Disabled"":null}}      eventhandlers.go:75: I0229 10:48:13.717736] Add event for node node=""node1""      node_tree.go:65: I0229 10:48:13.717988] Added node in listed group to NodeTree node=""node1"" zone=""""      eventhandlers.go:75: I0229 10:48:13.718196] Add event for node node=""node2""      node_tree.go:65: I0229 10:48:13.718385] Added node in listed group to NodeTree node=""node2"" zone=""""      eventhandlers.go:75: I0229 10:48:13.718588] Add event for node node=""node3""      node_tree.go:65: I0229 10:48:13.718793] Added node in listed group to NodeTree node=""node3"" zone=""""      eventhandlers.go:128: I0229 10:48:13.718980] Add event for unscheduled pod pod=""pod1""      scheduling_queue.go:595: I0229 10:48:13.719138] Pod moved to an internal scheduling queue pod=""pod1"" event=""PodAdd"" queue=""Active""      schedule_one.go:84: I0229 10:48:13.719250] About to try and schedule pod pod=""pod1""      schedule_one.go:97: I0229 10:48:13.719321] Attempting to schedule pod pod=""pod1""      framework.go:1475: I0229 10:48:13.719623] Permit: One or more plugins asked to wait and no plugin rejected pod node=""node1"" pod=""pod1""      framework.go:1500: I0229 10:48:13.719889] Pod waiting on permit pod=""pod1""      eventhandlers.go:128: I0229 10:48:13.720049] Add event for unscheduled pod pod=""pod2""      scheduling_queue.go:595: I0229 10:48:13.720184] Pod moved to an internal scheduling queue pod=""pod2"" event=""PodAdd"" queue=""Active""      schedule_one.go:84: I0229 10:48:13.720358] About to try and schedule pod pod=""pod2""      schedule_one.go:97: I0229 10:48:13.720451] Attempting to schedule pod pod=""pod2""      framework.go:1475: I0229 10:48:13.720791] Permit: One or more plugins asked to wait and no plugin rejected pod node=""node2"" pod=""pod2""      framework.go:1500: I0229 10:48:13.721010] Pod waiting on permit pod=""pod2""      eventhandlers.go:128: I0229 10:48:13.721439] Add event for unscheduled pod pod=""pod3""      scheduling_queue.go:595: I0229 10:48:13.721732] Pod moved to an internal scheduling queue pod=""pod3"" event=""PodAdd"" queue=""Active""      eventhandlers.go:128: I0229 10:48:13.721917] Add event for unscheduled pod pod=""pod4""      schedule_one.go:84: I0229 10:48:13.722078] About to try and schedule pod pod=""pod3""      schedule_one.go:97: I0229 10:48:13.722236] Attempting to schedule pod pod=""pod3""      scheduling_queue.go:595: I0229 10:48:13.722449] Pod moved to an internal scheduling queue pod=""pod4"" event=""PodAdd"" queue=""Active""      framework.go:1475: I0229 10:48:13.722729] Permit: One or more plugins asked to wait and no plugin rejected pod node=""node3"" pod=""pod3""      framework.go:1500: I0229 10:48:13.723032] Pod waiting on permit pod=""pod3""      schedule_one.go:84: I0229 10:48:13.723270] About to try and schedule pod pod=""pod4""      schedule_one.go:97: I0229 10:48:13.723413] Attempting to schedule pod pod=""pod4""      scheduler_test.go:1044: Unexpected waitingPods in scheduler profile test-scheduler-profile-1, expect: []string{""pod1"", ""pod2"", ""pod3"", ""pod4""}, got: []string{""pod1"", ""pod2"", ""pod3""}      --- FAIL: TestFrameworkHandler_IterateOverWaitingPods/pods_with_different_profiles_are_waiting_on_permit_stage (0.01s)  ```    #### Recent failures:  [3/1/2024, 7:14:16 AM pr:pull-kubernetes-unit](https://prow.k8s.io/view/gs/kubernetes-jenkins/pr-logs/pull/123614/pull-kubernetes-unit/1763538031354056704)  [2/29/2024, 5:28:43 AM pr:pull-kubernetes-unit](https://prow.k8s.io/view/gs/kubernetes-jenkins/pr-logs/pull/123555/pull-kubernetes-unit/1763149087500144640)  [2/28/2024, 12:17:55 PM pr:pull-kubernetes-unit](https://prow.k8s.io/view/gs/kubernetes-jenkins/pr-logs/pull/123562/pull-kubernetes-unit/1762889666685571072)      /kind failing-test  <!-- If this is a flake, please add: /kind flake -->  /kind flake    <!-- Please assign a SIG using: /sig SIG-NAME -->  /sig scheduling"
"283","Async wait","I/O","I/O","","","","Resolves : https://issues.apache.org/jira/browse/KAFKA-16518    - Adds a new argument ""standalone"" to kafka-storage.sh  - If standalone mode, creates a checkpoint file in metadata dir ${kafkaConfig.metadataLogDir}/__cluster_metadata-0/      ### Committer Checklist (excluded from commit message)  - [ ] Verify design and implementation   - [ ] Verify test coverage and CI build status  - [ ] Verify documentation (including upgrade notes)"
"285","Unordered collections","Time","Test order dependency","","","","PRs backported:    - #9909   - #9918  - #9919   - #9920  - #9922   - #9937   - #9938   - #9939   - #9940   - #9941   - #9948   - #9950   - #9953   - #9954   - #9961   - #9962   - #9963   - #9966   - #9967   - #9969  - #9971  - #9972   - #9934   - #9968   - use extension ref `release-1.9`"
"286","Async wait","Time","Network","","","","Fixes #10853    I think the issue is that we do DNS client request to the DNS caching server, and expect the request to fail on client side, as caching server doesn't respond in time (as the server is waiting for a response).    Make sure we use a short timeout on our client side, so that we time out before a server does."
"287","Async wait","Async wait","Concurrency","","","","This enables golangci-lint via build tags for integration tests (this  should have been done long ago!), and fixes the linting errors.    Two tests were updated to reduce flakiness:    * apply config: wait for nodes to issue ""boot done"" sequence event  before proceeding  * recover: kill pods even if they appear after the initial set gets  killed (potential race condition with previous test).    Signed-off-by: Andrey Smirnov <smirnov.andrey@gmail.com>"
"289","Async wait","Time","Time","","","","Fixes #1291    ### Motivation    The `MaxTime` setting for AckGroupingTracker is too short at only 10,000 nanoseconds.  This causes the test very flaky.    ### Modifications    - Change the `MaxTime` to 10 seconds    ### Verifying this change    This change is a trivial rework / code cleanup without any test coverage.      ### Does this pull request potentially affect one of the following parts:    *If `yes` was chosen, please highlight the changes*      - Dependencies (does it add or upgrade a dependency): (yes / no)    - The public API: (yes / no)    - The schema: (yes / no / don't know)    - The default values of configurations: (yes / no)    - The wire protocol: (yes / no)    ### Documentation      - Does this pull request introduce a new feature? (yes / no)    - If yes, how is the feature documented? (not applicable / docs / GoDocs / not documented)    - If a feature is not applicable for documentation, explain why?    - If a feature is not documented yet in this PR, please create a followup issue for adding the documentation"
"290","Test order dependency","I/O","I/O","","","","Follow-up of #10811 to ignore other types of `FileSystemException` like `DirectoryNotEmptyException` as well    ```  TestDataFrameWrites > testFaultToleranceOnWrite() > format = parquet FAILED      java.nio.file.DirectoryNotEmptyException: /tmp/junit-7768099913831474039/parquet/test          at java.base/sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:289)          at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:104)          at java.base/java.nio.file.Files.delete(Files.java:1152)          at org.apache.commons.io.FileUtils.delete(FileUtils.java:1222)          at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1242)          at org.apache.iceberg.spark.source.TestDataFrameWrites.testFaultToleranceOnWrite(TestDataFrameWrites.java:427)  ```    cc @Fokko @nastra"
"291","Randomness","Time","Test order dependency","","","","Closes #12889"
"293","Test order dependency","Time","Resource leak","","","","### Rationale for this change Fixing flaky bloom filter memory check test  ### What changes are included in this PR? Added an additional runtime.GC() call to ensure the releases are called."
"294","Concurrency","I/O","I/O","","","","### Rationale for this change Additional checks for `io.EOF` to avoid flaky tests"
"295","Async wait","Time","Time","","","","[PR Linked Issue] **Build Scans:** - [elasticsearch-intake #27235 / part4](https://gradle-enterprise.elastic.co/s/gf3w65zgpsugy) - [elasticsearch-pull-request #87067 / part-4](https://gradle-enterprise.elastic.co/s/ptir5haak4lju) - [elasticsearch-pull-request #87067 / part-4-fips](https://gradle-enterprise.elastic.co/s/2inhl3fgi7sae)  **Reproduction Line:** ``` ./gradlew "":x-pack:plugin:security:test"" --tests ""org.elasticsearch.xpack.security.authc.AuthenticationServiceTests.testInvalidToken"" -Dtests.seed=3801949404B71D88 -Dtests.locale=nl-SX -Dtests.timezone=Etc/Universal -Druntime.java=24 ```  **Applicable branches:** main  **Reproduces locally?:** N/A  **Failure History:** [See dashboard](https://es-delivery-stats.elastic.dev/app/dashboards#/view/dcec9e60-72ac-11ee-8f39-55975ded9e63?_g=(refreshInterval:(pause:!t,value:60000),time:(from:now-7d%2Fd,to:now))&_a=(controlGroupState:(initialChildControlState:('0c0c9cb8-ccd2-45c6-9b13-96bac4abc542':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:task.keyword,order:0,selectedOptions:!(),title:'GradleTask',type:optionsListControl),'4e6ad9d6-6fdc-4fcc-bf1a-aa6ca79e0850':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:className.keyword,order:1,selectedOptions:!(org.elasticsearch.xpack.security.authc.AuthenticationServiceTests),title:'Suite',type:optionsListControl),'144933da-5c1b-4257-a969-7f43455a7901':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:name.keyword,order:2,selectedOptions:!('testInvalidToken'),title:'Test',type:optionsListControl)))))  **Failure Message:** ``` java.lang.Exception: Test abandoned because suite timeout was reached. ```  **Issue Reasons:** - [main] 3 failures in test testInvalidToken (1.3% fail rate in 228 executions)  **Note:** This issue was created using new test triage automation. Please report issues or feedback to es-delivery."
"296","Randomness","Concurrency","Concurrency","","","","[PR Linked Issue] **Build Scans:** - [elasticsearch-intake #27158 / part3](https://gradle-enterprise.elastic.co/s/akaigagd47vke) - [elasticsearch-periodic-platform-support #10137 / rocky-9_platform-support-unix](https://gradle-enterprise.elastic.co/s/7266jgkv5xaqy)  **Reproduction Line:** ``` ./gradlew "":x-pack:plugin:esql:internalClusterTest"" --tests ""org.elasticsearch.xpack.esql.action.RandomizedTimeSeriesIT.testGroupByNothing"" -Dtests.seed=3050CE9CE9791881 -Dtests.locale=sa -Dtests.timezone=Australia/LHI -Druntime.java=24 ```  **Applicable branches:** main  **Reproduces locally?:** N/A  **Failure History:** [See dashboard](https://es-delivery-stats.elastic.dev/app/dashboards#/view/dcec9e60-72ac-11ee-8f39-55975ded9e63?_g=(refreshInterval:(pause:!t,value:60000),time:(from:now-7d%2Fd,to:now))&_a=(controlGroupState:(initialChildControlState:('0c0c9cb8-ccd2-45c6-9b13-96bac4abc542':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:task.keyword,order:0,selectedOptions:!(),title:'GradleTask',type:optionsListControl),'4e6ad9d6-6fdc-4fcc-bf1a-aa6ca79e0850':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:className.keyword,order:1,selectedOptions:!(org.elasticsearch.xpack.esql.action.RandomizedTimeSeriesIT),title:'Suite',type:optionsListControl),'144933da-5c1b-4257-a969-7f43455a7901':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:name.keyword,order:2,selectedOptions:!('testGroupByNothing'),title:'Test',type:optionsListControl)))))  **Failure Message:** ``` org.elasticsearch.action.bulk.IndexDocFailureStoreStatus$ExceptionWithFailureStoreStatus: [.ds-tsit_ds-2025.08.20-000001/TEfC-UbzS46u74MtBQWqXA][[.ds-tsit_ds-2025.08.20-000001][0]] org.elasticsearch.index.engine.VersionConflictEngineException: [C49S8X6g-QjW9uynAAABmMd3qH4][KBkJUGhjrYx0kKOigCXrLeK0RcVVTL_itQLi69ku_AIJqqsrijofpOU@2025-08-20T12:32:44.670Z]: version conflict, document already exists (current version [1]) ```  **Issue Reasons:** - [main] 2 failures in test testGroupByNothing (1.7% fail rate in 118 executions)  **Note:** This issue was created using new test triage automation. Please report issues or feedback to es-delivery."
"297","Concurrency","Async wait","Test order dependency","","","","[PR Linked Issue] **Build Scans:** - [elasticsearch-periodic-platform-support #9255 / windows-2025_checkpart1_platform-support-windows](https://gradle-enterprise.elastic.co/s/wrqmjkr2q5tv2) - [elasticsearch-periodic-platform-support #9227 / amazonlinux-2023_platform-support-aws](https://gradle-enterprise.elastic.co/s/lnzqxbgk5pjyi) - [elasticsearch-periodic-platform-support #9227 / oraclelinux-9_platform-support-unix](https://gradle-enterprise.elastic.co/s/bc573kel6n2ae)  **Reproduction Line:** ``` gradlew "":server:internalClusterTest"" --tests ""org.elasticsearch.search.aggregations.bucket.FiltersCancellationIT.testFiltersSubAggsCancellation"" -Dtests.seed=E591B05A93049B8B -Dtests.locale=fr-TG -Dtests.timezone=US/Eastern -Druntime.java=24 ```  **Applicable branches:** main  **Reproduces locally?:** N/A  **Failure History:** [See dashboard](https://es-delivery-stats.elastic.dev/app/dashboards#/view/dcec9e60-72ac-11ee-8f39-55975ded9e63?_g=(refreshInterval:(pause:!t,value:60000),time:(from:now-7d%2Fd,to:now))&_a=(controlGroupState:(initialChildControlState:('0c0c9cb8-ccd2-45c6-9b13-96bac4abc542':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:task.keyword,order:0,selectedOptions:!(),title:'GradleTask',type:optionsListControl),'4e6ad9d6-6fdc-4fcc-bf1a-aa6ca79e0850':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:className.keyword,order:1,selectedOptions:!(org.elasticsearch.search.aggregations.bucket.FiltersCancellationIT),title:'Suite',type:optionsListControl),'144933da-5c1b-4257-a969-7f43455a7901':(dataViewId:fbbdc689-be23-4b3d-8057-aa402e9ed0c5,fieldName:name.keyword,order:2,selectedOptions:!('testFiltersSubAggsCancellation'),title:'Test',type:optionsListControl)))))  **Failure Message:** ``` java.lang.AssertionError: null ```  **Issue Reasons:** - [main] 3 failures in test testFiltersSubAggsCancellation (1.1% fail rate in 263 executions) - [main] 2 failures in pipeline elasticsearch-periodic-platform-support (40.0% fail rate in 5 executions)  **Note:** This issue was created using new test triage automation. Please report issues or feedback to es-delivery."
"301","Randomness","Concurrency","Concurrency","","","","## PR Summary    Since parametrizing the test allows it to run in parallel, this makes it flaky, as one process can overwrite the test result image of another.    Our standard way for dealing with tests that use the same baseline image is to pass duplicate filenames to `image_comparison`, because that is serialized.    This is basically the same as #16656 for `test_stem`.    ## PR Checklist    - [x] Has Pytest style unit tests  - [x] Code is [Flake 8](http://flake8.pycqa.org/en/latest/) compliant  - [N/A] New features are documented, with examples if plot related  - [N/A] Documentation is sphinx and numpydoc compliant  - [N/A] Added an entry to doc/users/next_whats_new/ if major new feature (follow instructions in README.rst there)  - [N/A] Documented in doc/api/api_changes.rst if API changed in a backward-incompatible way"
"302","Concurrency","Randomness","Randomness","","","","## PR summary    For labelcolor={linecolor,markeredgecolor,markerfacecolor}, text will match the specified attribute if consistent, but fall back to black if they differ within a single labeled artist.    These tests use 10 random colours out of the ['r', 'g', 'b'] set, so 3 (all red, all green, all blue) out of 3**10 will result in the text _not_ being black. This is rare (0.0051%), but does happen once in a while (e.g., https://github.com/matplotlib/matplotlib/actions/runs/10967975776/job/30458622005).    Instead, just hard-code some different colours in the test.    ## PR checklist    - [n/a] ""closes #0000"" is in the body of the PR description to [link the related issue](https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue)  - [x] new and changed code is [tested](https://matplotlib.org/devdocs/devel/testing.html)  - [n/a] *Plotting related* features are demonstrated in an [example](https://matplotlib.org/devdocs/devel/document.html#write-examples-and-tutorials)  - [n/a] *New Features* and *API Changes* are noted with a [directive and release note](https://matplotlib.org/devdocs/devel/api_changes.html#announce-changes-deprecations-and-new-features)  - [n/a] Documentation complies with [general](https://matplotlib.org/devdocs/devel/document.html#write-rest-pages) and [docstring](https://matplotlib.org/devdocs/devel/document.html#write-docstrings) guidelines"
"305","Floating point operations","Time","Floating point operations","","","","Further lower threshold for F64 in //xla/service/gpu/model:hlo_op_profiler_test  This was originally proposed in https://github.com/openxla/xla/pull/16102, but I still ran into issue where it failed by slight margin:  ``` Expected: (profiler.MeasureClockCyclesPerOp(HloOpcode::kDivide, F64) .value() .clock_cycles()) > (300), actual: 296 vs 300 ```  That said, I ran 1000 tests and did not encounter this issue. Reducing the threshold to 280 since the bound seems very close and flaky test is no good either way."
"306","Test order dependency","I/O","Test order dependency","","","","[IFRT] Remove the error message mentioning an invalid output target  A log message was being generated when an invalid output target was specified and being ignored. This caused some OSS tests to fail in a flaky manner, so logging is removed in this change."
"307","Test order dependency","Async wait","Async wait","","","","[PR Linked Issue] A test failed on a tracked branch  ``` StaleElementReferenceError: stale element reference: stale element not found in the current frame   (Session info: chrome=123.0.6312.105)     at Object.throwDecodedError (node_modules/selenium-webdriver/lib/error.js:521:15)     at parseHttpResponse (node_modules/selenium-webdriver/lib/http.js:510:13)     at Executor.execute (node_modules/selenium-webdriver/lib/http.js:443:28)     at processTicksAndRejections (node:internal/process/task_queues:95:5)     at Task.exec (prevent_parallel_calls.ts:28:20) {   remoteStacktrace: '#0 0x562f61afa873 <unknown>\n' +     '#1 0x562f617f08c6 <unknown>\n' +     '#2 0x562f617f5e75 <unknown>\n' +     '#3 0x562f617f7bce <unknown>\n' +     '#4 0x562f617f7c5c <unknown>\n' +     '#5 0x562f61835ae2 <unknown>\n' +     '#6 0x562f6185d5a2 <unknown>\n' +     '#7 0x562f6182fe98 <unknown>\n' +     '#8 0x562f6185d76e <unknown>\n' +     '#9 0x562f6187bc19 <unknown>\n' +     '#10 0x562f6185d343 <unknown>\n' +     '#11 0x562f6182e593 <unknown>\n' +     '#12 0x562f6182ef5e <unknown>\n' +     '#13 0x562f61abe85b <unknown>\n' +     '#14 0x562f61ac27b5 <unknown>\n' +     '#15 0x562f61aac581 <unknown>\n' +     '#16 0x562f61ac3342 <unknown>\n' +     '#17 0x562f61a9188f <unknown>\n' +     '#18 0x562f61ae9738 <unknown>\n' +     '#19 0x562f61ae990b <unknown>\n' +     '#20 0x562f61af99c4 <unknown>\n' +     '#21 0x7fbdefe8b609 start_thread\n' } ```  First failure: [CI Build - main](https://buildkite.com/elastic/kibana-on-merge/builds/43375#018eb290-51a2-49ec-a9c7-a34017c17388)  <!-- kibanaCiData = {""failed-test"":{""test.class"":""Chrome X-Pack UI Functional Tests.x-pack/test/functional/apps/lens/group4/show_underlying_data_dashboard¬∑ts"",""test.name"":""lens app - group 4 lens show underlying data from dashboard should bring both dashboard context and visualization context to discover"",""test.failCount"":2}} -->"
"311","Test order dependency","Concurrency","Concurrency","","","","* remove casts  * generalize `is_valid_sample_rate` to return the validated float  * added a `validate_scopes` helper method to validate the scopes entry on the context and return the narrowed type  * added a `get_typed_attribute` helper method to narrow the type on getting attributes from otel  * fix a flaky test on gevent"
"312","Concurrency","Async wait","Async wait","","","","### What changes were proposed in this pull request?  This PR aims to fix flaky tests in `SparkConnectServiceSuite` which are caused by `executorHolder` [undefined](https://github.com/apache/spark/blob/ab9a63626018156b3e0f267f14409c30031692b7/sql/connect/server/src/test/scala/org/apache/spark/sql/connect/planner/SparkConnectServiceSuite.scala#L908).  The conditions to reproduce this issue are:    (1) The operation finishes before its `executeHolder` is set in [MockSparkListener#onOtherEvent](https://github.com/apache/spark/blob/ab9a63626018156b3e0f267f14409c30031692b7/sql/connect/server/src/test/scala/org/apache/spark/sql/connect/planner/SparkConnectServiceSuite.scala#L961).  (2) `executeHolder` is accessed through calling `verifyEvents.onComplete` after the operation finishes.     `SparkListenerConnectOperationStarted` is posted asynchronously with the corresponding operation so the condition (1) can be met. After an operation finishes, `executeHolder` is [removed from a map](https://github.com/apache/spark/blob/af16aa8e11c223642f928b0b9893854a851d70bb/sql/connect/server/src/main/scala/org/apache/spark/sql/connect/service/SparkConnectExecutionManager.scala#L153) so if the condition (1) is met, `executeHolder` is never set because `SparkConnectService.executionManager.getExecuteHolder` consistently returns `None`.    One example of the test affected by this issue is `SPARK-43923: commands send events - get_resources_command`.  You can easily reproduce this issue by inserting sleep into `MockSparkListener#onOtherEvent` like as follows.    ```     val executeKey =       ExecuteKey(sessionHolder.userId, sessionHolder.sessionId, e.operationId)  +  Thread.sleep(1000)     executeHolder = SparkConnectService.executionManager.getExecuteHolder(executeKey)  ```    And then, run test.  ```  $ build/sbt 'connect/testOnly org.apache.spark.sql.connect.planner.SparkConnectServiceSuite -- -z ""get_resources_command""'  ```  To resolve this issue, this PR proposes:    * Change `VerifyEvents#onCompleted` just to assert `executeHolder.eventsManager.getProducedRowCount == producedRowCount`  * Call `VerifyEvents#onCompleted` from `StreamObserver#onCompleted`  * Add `VerifyEvents#assertClosed` to check if the status is `Closed`    ### Why are the changes needed?  For test stability.    ### Does this PR introduce _any_ user-facing change?  No.    ### How was this patch tested?  Inserting `Thread.sleep(1000)` like mentioned above and then run `SparkConnectServiceSuite`.    ### Was this patch authored or co-authored using generative AI tooling?  No."
"314","Async wait","Concurrency","Test order dependency","","","","This PR moves the topic creation before consumer creations in `PlaintextAdminIntegrationTest.testListGroups`, to avoid potential errors if consumer creates topic due to metadata update.  See discussion https://github.com/apache/kafka/pull/20244#discussion_r2325557949  Reviewers: @chia7712, bbejeck@apache.org"
"316","OS","Time","Test order dependency","","","","### Motivation  I'm making this change for clarification in the Getting Started guide which is the gateway for new users to Pulsar. ### Modifications  Updated documentation. ### Result  Just the documentation."
"319","Async wait","I/O","I/O","","","","This issue can be caused by a non-existing path but also a misunderstanding from the config file. A short example will help the user."
"320","Time","Time","Test order dependency","","","","<!--  Thank you for contributing! Please make sure that your code changes  are covered with tests. And in case of new features or big changes  remember to adjust the documentation.    Feel free to ping committers for the review!    In case of an existing issue, reference it using one of the following:    closes: #ISSUE  related: #ISSUE    How to write a good git commit message:  http://chris.beams.io/posts/git-commit/  -->    ---  **^ Add meaningful description above**    Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.  In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.  In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).  In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments)."
"326","Async wait","Async wait","Time","","","","Set `getNumHomes: 1` to enable the 567 ms or 2 seconds of wait for the server to be ready in `TestServerPathEncodingIssues/Unicode_paths` and `TestServerPathEncodingIssues/Windows_multilingual_404`.    Fixes #10332    ---    Hi @bep, I hope this is the right fix.  Besides waiting for the GitHub Actions CI test result, I'll be uploading 0.104.2-2 to Debian shortly and will report back if these tests pass the very first time on all architectures."
"328","Async wait","Time","Network","","","","[PR Linked Issue] `contentTracing captured events include V8 samples from the main process` has been flaking a fair amount on Appveyor as of late.    See [here](https://ci.appveyor.com/project/electron-bot/electron-x64-testing/builds/47184539/job/6ycj2f45a7flb0dc/tests) for example."
"330","Async wait","Async wait","Time","","","","#### Description of Change I'm not sure what event to hook here, so poll instead.  #### Checklist <!-- Remove items that do not apply. For completed items, change [ ] to [x]. -->  - [x] PR description included and stakeholders cc'd - [x] `npm test` passes - [x] tests are [changed or added](https://github.com/electron/electron/blob/master/docs/development/testing.md) - [x] PR title follows semantic [commit guidelines](https://github.com/electron/electron/blob/master/docs/development/pull-requests.md#commit-message-guidelines) - [x] This is **NOT A BREAKING CHANGE**. Breaking changes may not be merged to master until 11-x-y is branched.  #### Release Notes  Notes: none"
"336","Randomness","Time","Concurrency","","","","Let's test CI.."
"337","Async wait","Network","Unordered collections","","","","Removed white supremacist language."
"338","Concurrency","Async wait","Async wait","","","","This PR implements the Fullscreen API.     The final commit also adds some Qt UI (an ""exit fullscreen"" button that animates from the top down, sort of like how Chrome does it, and also Firefox). For Qt-backends, the escape key also exits out of fullscreen, fully.    The spec can be found [here](https://fullscreen.spec.whatwg.org/).    New web platform test results (fullscreen/api) with this patch series applied:    ```  Ran 57 tests finished in 13.7 seconds.    ‚Ä¢ 36 ran as expected. 0 tests skipped.    ‚Ä¢ 1 tests had errors unexpectedly    ‚Ä¢ 1 tests timed out unexpectedly    ‚Ä¢ 21 tests had unexpected subtest results  ```  (up from 0 expected to 36. Another test succeeds when #4329 is applied)    Additional work that needs to happen:  - https://fullscreen.spec.whatwg.org/#dom-document-fullscreenenabled needs to be implemented fully, where a document's ""allowed to use"" can be deterimined by the `allowFullscreen` attribute set on an iframe. This attribute can not be changed dynamically and once set for a document, is set for the rest of it's life time.    Additional work that's required can be determined by the WPT suite."
"340","Unordered collections","Unordered collections","Test order dependency","","","","I am aware of a case where the same set of plugins would lead to one controller starting successfully and one controller failing to start, depending on the order in which the plugins were listed. We currently use file system iteration order, which is undefined. This PR sorts the list by filename before passing the result to the topological sorting function, so every controller with the same set of plugins will now load them in the same order. This should make it easier to debug such problems, because they will either always occur, or they will never occur ‚Äî but at least the behavior will be deterministic.    ### Testing done    I added a log statement to print the list of active plugins as consumed by the `UberClassLoader` and verified that at each level of the topological sort the entries were in lexicographical order.    ### Proposed changelog entries    List plugins in deterministic order to improve diagnosability of plugin linkage errors.    ### Proposed upgrade guidelines    N/A    ```[tasklist]  ### Submitter checklist  - [ ] The Jira issue, if it exists, is well-described.  - [ ] The changelog entries and upgrade guidelines are appropriate for the audience affected by the change (users or developers, depending on the change) and are in the imperative mood (see [examples](https://github.com/jenkins-infra/jenkins.io/blob/master/content/_data/changelogs/weekly.yml)). Fill in the **Proposed upgrade guidelines** section only if there are breaking changes or changes that may require extra steps from users during upgrade.  - [ ] There is automated testing or an explanation as to why this change has no tests.  - [ ] New public classes, fields, and methods are annotated with `@Restricted` or have `@since TODO` Javadocs, as appropriate.  - [ ] New deprecations are annotated with `@Deprecated(since = ""TODO"")` or `@Deprecated(forRemoval = true, since = ""TODO"")`, if applicable.  - [ ] New or substantially changed JavaScript is not defined inline and does not call `eval` to ease future introduction of Content Security Policy (CSP) directives (see [documentation](https://www.jenkins.io/doc/developer/security/csp/)).  - [ ] For dependency updates, there are links to external changelogs and, if possible, full differentials.  - [ ] For new APIs and extension points, there is a link to at least one consumer.  ```    ### Desired reviewers    @mention    <!-- Comment:  If you need an accelerated review process by the community (e.g., for critical bugs), mention @jenkinsci/core-pr-reviewers.  -->    Before the changes are marked as `ready-for-merge`:    ```[tasklist]  ### Maintainer checklist  - [ ] There are at least two (2) approvals for the pull request and no outstanding requests for change.  - [ ] Conversations in the pull request are over, or it is explicit that a reviewer is not blocking the change.  - [ ] Changelog entries in the pull request title and/or **Proposed changelog entries** are accurate, human-readable, and in the imperative mood.  - [ ] Proper changelog labels are set so that the changelog can be generated automatically.  - [ ] If the change needs additional upgrade steps from users, the `upgrade-guide-needed` label is set and there is a **Proposed upgrade guidelines** section in the pull request title (see [example](https://github.com/jenkinsci/jenkins/pull/4387)).  - [ ] If it would make sense to backport the change to LTS, a Jira issue must exist, be a _Bug_ or _Improvement_, and be labeled as `lts-candidate` to be considered (see [query](https://issues.jenkins.io/issues/?filter=12146)).  ```    <a href=""https://gitpod.io/#https://github.com/jenkinsci/jenkins/pull/8453""><img src=""https://gitpod.io/button/open-in-gitpod.svg""/></a>"
"342","Time","Time","Test order dependency","","","","(cherry picked from commit 28278debebabdd44bf69609f17d2c7c9c8a39695)    <!--   Licensed to the Apache Software Foundation (ASF) under one   or more contributor license agreements.  See the NOTICE file   distributed with this work for additional information   regarding copyright ownership.  The ASF licenses this file   to you under the Apache License, Version 2.0 (the   ""License""); you may not use this file except in compliance   with the License.  You may obtain a copy of the License at       http://www.apache.org/licenses/LICENSE-2.0     Unless required by applicable law or agreed to in writing,   software distributed under the License is distributed on an   ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY   KIND, either express or implied.  See the License for the   specific language governing permissions and limitations   under the License.   -->    <!--  Thank you for contributing! Please make sure that your code changes  are covered with tests. And in case of new features or big changes  remember to adjust the documentation.    Feel free to ping committers for the review!    In case of an existing issue, reference it using one of the following:    closes: #ISSUE  related: #ISSUE    How to write a good git commit message:  http://chris.beams.io/posts/git-commit/  -->        <!-- Please keep an empty line above the dashes. -->  ---  **^ Add meaningful description above**  Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.  In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.  In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).  In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [airflow-core/newsfragments](https://github.com/apache/airflow/tree/main/airflow-core/newsfragments)."
"344","Concurrency","Concurrency","Async wait","","","","As documented in #33323, we have frequent failures of the flaky triggerer job tests.    The flaky failures are about some errors when we close all the sessions in teardown of the test. It turns out that the tests had side-effect - they have not waited for the TriggererJob thread to complete, they merely marked them to be stopped, but they have not waited for those to complete - this is quite plausible explanation of the flaky test failures - since those threads have 1 second sleep, it's more than likely that the session has been created and used by the thread while the teardown has been attempting to close all the sessions.    This side effect could also have an effect for other tests that were run after - because in a busy test run machine, the side effects could propagate further than just to the teardown, so it could also explain why sometimes (very rarely) other job tests failed with similar errors.    The fix is to join the runner after marking it to be stopped.    Fixes: #33323 (Hopefully)    <!--   Licensed to the Apache Software Foundation (ASF) under one   or more contributor license agreements.  See the NOTICE file   distributed with this work for additional information   regarding copyright ownership.  The ASF licenses this file   to you under the Apache License, Version 2.0 (the   ""License""); you may not use this file except in compliance   with the License.  You may obtain a copy of the License at       http://www.apache.org/licenses/LICENSE-2.0     Unless required by applicable law or agreed to in writing,   software distributed under the License is distributed on an   ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY   KIND, either express or implied.  See the License for the   specific language governing permissions and limitations   under the License.   -->    <!--  Thank you for contributing! Please make sure that your code changes  are covered with tests. And in case of new features or big changes  remember to adjust the documentation.    Feel free to ping committers for the review!    In case of an existing issue, reference it using one of the following:    closes: #ISSUE  related: #ISSUE    How to write a good git commit message:  http://chris.beams.io/posts/git-commit/  -->        <!-- Please keep an empty line above the dashes. -->  ---  **^ Add meaningful description above**  Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/CONTRIBUTING.rst#pull-request-guidelines)** for more information.  In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.  In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).  In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments)."
"349","Randomness","Test order dependency","Unordered collections","","","","There is some flakiness for the checked error messages, as some include a ""verification_error:"" prefix. I've used regexes to avoid that, and removing the line / character information on the error being checked."
"351","Concurrency","Time","Unordered collections","","","","Corrected Spelling errors."
"353","Async wait","I/O","I/O","","","","This issue can be caused by a non-existing path but also a misunderstanding from the config file. A short example will help the user."
"362","Time","Unordered collections","Test order dependency","","","","<!--  Thanks for sending a pull request!  Here are some tips for you:    1. If this is your first time, please read our contributor guidelines: https://git.k8s.io/community/contributors/guide/first-contribution.md#your-first-contribution and developer guide https://git.k8s.io/community/contributors/devel/development.md#development-guide  2. Please label this pull request according to what type of issue you are addressing, especially if this is a release targeted pull request. For reference on required PR/issue labels, read here:  https://git.k8s.io/community/contributors/devel/sig-release/release.md#issuepr-kind-label  3. Ensure you have added or ran the appropriate tests for your PR: https://git.k8s.io/community/contributors/devel/sig-testing/testing.md  4. If you want *faster* PR reviews, read how: https://git.k8s.io/community/contributors/guide/pull-requests.md#best-practices-for-faster-reviews  5. If the PR is unfinished, see how to mark it: https://git.k8s.io/community/contributors/guide/pull-requests.md#marking-unfinished-pull-requests  -->    #### What type of PR is this?  /kind bug  <!--  Add one of the following kinds:  /kind bug  /kind cleanup  /kind documentation  /kind feature    Optionally add one or more of the following kinds if applicable:  /kind api-change  /kind deprecation  /kind failing-test  /kind flake  /kind regression  -->    #### What this PR does / why we need it:  fix flaky test on dra manager_test.go  #### Which issue(s) this PR fixes:  <!--  *Automatically closes linked issue when PR is merged.  Usage: `Fixes #<issue number>`, or `Fixes (paste link of issue)`.  _If PR is about `failing-tests or flakes`, please post the related issues/tests in a comment and do not use `Fixes`_*  -->  Fixes #119701    #### Special notes for your reviewer:    #### Does this PR introduce a user-facing change?  <!--  If no, just write ""NONE"" in the release-note block below.  If yes, a release note is required:  Enter your extended release note in the block below. If the PR requires additional action from users switching to the new release, include the string ""action required"".    For more information on release notes see: https://git.k8s.io/community/contributors/guide/release-notes.md  -->  ```release-note    ```    #### Additional documentation e.g., KEPs (Kubernetes Enhancement Proposals), usage docs, etc.:    <!--  This section can be blank if this pull request does not require a release note.    When adding links which point to resources within git repositories, like  KEPs or supporting documentation, please reference a specific commit and avoid  linking directly to the master branch. This ensures that links reference a  specific point in time, rather than a document that may change over time.    See here for guidance on getting permanent links to files: https://help.github.com/en/articles/getting-permanent-links-to-files    Please use the following format for linking documentation:  - [KEP]: <link>  - [Usage]: <link>  - [Other doc]: <link>  -->  ```docs    ```"
"363","I/O","Time","Time","","","","<!--  Thanks for sending a pull request!  Here are some tips for you:    1. If this is your first time, please read our contributor guidelines: https://git.k8s.io/community/contributors/guide/first-contribution.md#your-first-contribution and developer guide https://git.k8s.io/community/contributors/devel/development.md#development-guide  2. Please label this pull request according to what type of issue you are addressing, especially if this is a release targeted pull request. For reference on required PR/issue labels, read here:  https://git.k8s.io/community/contributors/devel/sig-release/release.md#issuepr-kind-label  3. Ensure you have added or ran the appropriate tests for your PR: https://git.k8s.io/community/contributors/devel/sig-testing/testing.md  4. If you want *faster* PR reviews, read how: https://git.k8s.io/community/contributors/guide/pull-requests.md#best-practices-for-faster-reviews  5. If the PR is unfinished, see how to mark it: https://git.k8s.io/community/contributors/guide/pull-requests.md#marking-unfinished-pull-requests  -->    #### What type of PR is this?    /kind flake    #### What this PR does / why we need it:    **Kubelet logs:**    ```  // The container probe is failed  Feb 15 08:13:03 kind-worker kubelet[285]: I0215 08:13:03.197112     285 prober.go:153] ""Exec-Probe runProbe"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" containerName=""test-container-subpath-configmap-h8zg"" execCommand=[""sh"",""-c"",""cat /probe-volume/probe-file || test `cat /test-volume` = 'configmap-modified-value'""]  Feb 15 08:13:03 kind-worker kubelet[285]: I0215 08:13:03.905819     285 prober.go:120] ""Probe failed"" probeType=""Liveness"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" podUID=""c9f2f574-b2f4-49c0-a94f-c452d6290215"" containerName=""test-container-subpath-configmap-h8zg"" probeResult=""failure"" output=<    // kubelet tried to stop the container via calling container runtime  Feb 15 08:13:03 kind-worker kubelet[285]: I0215 08:13:03.910529     285 kuberuntime_manager.go:1148] ""computePodActions got for pod"" podActions=""KillPod: false, CreateSandbox: false, UpdatePodResources: false, Attempt: 0, InitContainersToStart: [], ContainersToStart: [0], EphemeralContainersToStart: [],ContainersToUpdate: map[], ContainersToKill: map[{containerd 89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1}:{0xc000b59c08 test-container-subpath-configmap-h8zg Container test-container-subpath-configmap-h8zg failed liveness probe, will be restarted LivenessProbe}]"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg""  Feb 15 08:13:03 kind-worker kubelet[285]: I0215 08:13:03.910732     285 kuberuntime_manager.go:1182] ""Killing unwanted container for pod"" containerName=""test-container-subpath-configmap-h8zg"" containerID={""Type"":""containerd"",""ID"":""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1""} pod=""subpath-2059/pod-subpath-test-configmap-h8zg""  Feb 15 08:13:03 kind-worker kubelet[285]: I0215 08:13:03.910919     285 kuberuntime_container.go:809] ""Killing container with a grace period"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" podUID=""c9f2f574-b2f4-49c0-a94f-c452d6290215"" containerName=""test-container-subpath-configmap-h8zg"" containerID=""containerd://89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1"" gracePeriod=2  Feb 15 08:13:03 kind-worker kubelet[285]: I0215 08:13:03.912334     285 event.go:389] ""Event occurred"" object=""subpath-2059/pod-subpath-test-configmap-h8zg"" fieldPath=""spec.containers{test-container-subpath-configmap-h8zg}"" kind=""Pod"" apiVersion=""v1"" type=""Normal"" reason=""Killing"" message=""Container test-container-subpath-configmap-h8zg failed liveness probe, will be restarted""  ```    **Containerd logs:**     ```  # Killing container with a grace period but timeout is reached  Feb 15 08:13:03 kind-worker containerd[185]: time=""2025-02-15T08:13:03.912504992Z"" level=info msg=""StopContainer for \""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"" with timeout 2 (s)""  Feb 15 08:13:03 kind-worker containerd[185]: time=""2025-02-15T08:13:03.913797826Z"" level=info msg=""Stop container \""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"" with signal terminated""    # Force killing the container but the container is already exited  Feb 15 08:13:03 kind-worker containerd[185]: time=""2025-02-15T08:13:03.976463751Z"" level=info msg=""received exit event container_id:\""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"" id:\""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"" pid:225289 exited_at:{seconds:1739607183 nanos:962757445}""  Feb 15 08:13:03 kind-worker containerd[185]: time=""2025-02-15T08:13:03.977725541Z"" level=info msg=""TaskExit event in podsandbox handler container_id:\""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"" id:\""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"" pid:225289 exited_at:{seconds:1739607183 nanos:962757445}""  Feb 15 08:13:05 kind-worker containerd[185]: time=""2025-02-15T08:13:05.954244737Z"" level=info msg=""Kill container \""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\""""  Feb 15 08:13:13 kind-worker containerd[185]: time=""2025-02-15T08:13:12.797190089Z"" level=error msg=""StopContainer for \""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"" failed"" error=""rpc error: code = Unknown desc = failed to kill container \""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"": ttrpc: closed""  ```    **Kubelet logs:**     ```  // kubelet fails to stop the container and the containerd returns an error  Feb 15 08:13:13 kind-worker kubelet[285]: E0215 08:13:12.800578     285 kuberuntime_container.go:814] ""Container termination failed with gracePeriod"" err=""rpc error: code = Unknown desc = failed to kill container \""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"": ttrpc: closed"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" podUID=""c9f2f574-b2f4-49c0-a94f-c452d6290215"" containerName=""test-container-subpath-configmap-h8zg"" containerID=""containerd://89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1"" gracePeriod=2  Feb 15 08:13:13 kind-worker kubelet[285]: E0215 08:13:12.800970     285 kuberuntime_manager.go:1187] ""killContainer for pod failed"" err=""rpc error: code = Unknown desc = failed to kill container \""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"": ttrpc: closed"" containerName=""test-container-subpath-configmap-h8zg"" containerID={""Type"":""containerd"",""ID"":""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1""} pod=""subpath-2059/pod-subpath-test-configmap-h8zg""  Feb 15 08:13:13 kind-worker kubelet[285]: I0215 08:13:12.801016     285 kubelet.go:1859] ""SyncPod exit"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" podUID=""c9f2f574-b2f4-49c0-a94f-c452d6290215"" isTerminal=false  Feb 15 08:13:13 kind-worker kubelet[285]: E0215 08:13:12.801142     285 pod_workers.go:1301] ""Error syncing pod, skipping"" err=""failed to \""KillContainer\"" for \""test-container-subpath-configmap-h8zg\"" with KillContainerError: \""rpc error: code = Unknown desc = failed to kill container \\\""89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\\\"": ttrpc: closed\"""" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" podUID=""c9f2f574-b2f4-49c0-a94f-c452d6290215""  Feb 15 08:13:13 kind-worker kubelet[285]: I0215 08:13:12.801177     285 pod_workers.go:1338] ""Processing pod event done"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" podUID=""c9f2f574-b2f4-49c0-a94f-c452d6290215"" updateType=""sync""    // The exitCode of The container `test-container-subpath-configmap-h8zg` is 0.  Feb 15 08:13:14 kind-worker kubelet[285]: I0215 08:13:14.214763     285 helpers.go:104] ""Already successfully ran container, do nothing"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" containerName=""test-container-subpath-configmap-h8zg""  Feb 15 08:13:14 kind-worker kubelet[285]: I0215 08:13:14.214879     285 kuberuntime_manager.go:1148] ""computePodActions got for pod"" podActions=""KillPod: false, CreateSandbox: false, UpdatePodResources: false, Attempt: 0, InitContainersToStart: [], ContainersToStart: [], EphemeralContainersToStart: [],ContainersToUpdate: map[], ContainersToKill: map[]"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg""  Feb 15 08:13:14 kind-worker kubelet[285]: I0215 08:13:14.215172     285 container_manager.go:238] ""Pod contains no container with pinned cpus"" podName=""pod-subpath-test-configmap-h8zg""  Feb 15 08:13:14 kind-worker kubelet[285]: I0215 08:13:14.215210     285 kuberuntime_sandbox_linux.go:62] ""Enforcing CFS quota"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" unlimited=false  Feb 15 08:13:14 kind-worker kubelet[285]: I0215 08:13:14.215232     285 kubelet.go:1859] ""SyncPod exit"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" podUID=""c9f2f574-b2f4-49c0-a94f-c452d6290215"" isTerminal=false  Feb 15 08:13:14 kind-worker kubelet[285]: I0215 08:13:14.215258     285 pod_workers.go:1338] ""Processing pod event done"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" podUID=""c9f2f574-b2f4-49c0-a94f-c452d6290215"" updateType=""sync""  Feb 15 08:13:14 kind-worker kubelet[285]: I0215 08:13:14.259606     285 status_manager.go:935] ""Patch status for pod"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" podUID=""c9f2f574-b2f4-49c0-a94f-c452d6290215"" patch=""{\""metadata\"":{\""uid\"":\""c9f2f574-b2f4-49c0-a94f-c452d6290215\""},\""status\"":{\""$setElementOrder/conditions\"":[{\""type\"":\""PodReadyToStartContainers\""},{\""type\"":\""Initialized\""},{\""type\"":\""Ready\""},{\""type\"":\""ContainersReady\""},{\""type\"":\""PodScheduled\""}],\""conditions\"":[{\""lastTransitionTime\"":\""2025-02-15T08:13:14Z\"",\""message\"":\""containers with unready status: [test-container-subpath-configmap-h8zg]\"",\""reason\"":\""ContainersNotReady\"",\""status\"":\""False\"",\""type\"":\""Ready\""},{\""lastTransitionTime\"":\""2025-02-15T08:13:14Z\"",\""message\"":\""containers with unready status: [test-container-subpath-configmap-h8zg]\"",\""reason\"":\""ContainersNotReady\"",\""status\"":\""False\"",\""type\"":\""ContainersReady\""}],\""containerStatuses\"":[{\""containerID\"":\""containerd://89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"",\""image\"":\""registry.k8s.io/e2e-test-images/busybox:1.36.1-1\"",\""imageID\"":\""registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9\"",\""lastState\"":{},\""name\"":\""test-container-subpath-configmap-h8zg\"",\""ready\"":false,\""restartCount\"":0,\""started\"":false,\""state\"":{\""terminated\"":{\""containerID\"":\""containerd://89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1\"",\""exitCode\"":0,\""finishedAt\"":\""2025-02-15T08:13:03Z\"",\""reason\"":\""Completed\"",\""startedAt\"":\""2025-02-15T08:12:57Z\""}},\""volumeMounts\"":[{\""mountPath\"":\""/test-volume\"",\""name\"":\""test-volume\""},{\""mountPath\"":\""/probe-volume\"",\""name\"":\""liveness-probe-volume\""},{\""mountPath\"":\""/var/run/secrets/kubernetes.io/serviceaccount\"",\""name\"":\""kube-api-access-d7bjr\"",\""readOnly\"":true,\""recursiveReadOnly\"":\""Disabled\""}]},{\""containerID\"":\""containerd://b83d07f353e6c10960e144839d90c658f1f40aea77ea78a9483620e33f98b67b\"",\""image\"":\""registry.k8s.io/e2e-test-images/busybox:1.36.1-1\"",\""imageID\"":\""registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9\"",\""lastState\"":{},\""name\"":\""test-container-volume-configmap-h8zg\"",\""ready\"":true,\""restartCount\"":0,\""started\"":true,\""state\"":{\""running\"":{\""startedAt\"":\""2025-02-15T08:12:58Z\""}},\""volumeMounts\"":[{\""mountPath\"":\""/test-volume\"",\""name\"":\""test-volume\""},{\""mountPath\"":\""/probe-volume\"",\""name\"":\""liveness-probe-volume\""},{\""mountPath\"":\""/var/run/secrets/kubernetes.io/serviceaccount\"",\""name\"":\""kube-api-access-d7bjr\"",\""readOnly\"":true,\""recursiveReadOnly\"":\""Disabled\""}]}]}}""  Feb 15 08:13:14 kind-worker kubelet[285]: I0215 08:13:14.259762     285 status_manager.go:944] ""Status for pod updated successfully"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" statusVersion=5 status={""phase"":""Running"",""conditions"":[{""type"":""PodReadyToStartContainers"",""status"":""True"",""lastProbeTime"":null,""lastTransitionTime"":""2025-02-15T08:12:55Z""},{""type"":""Initialized"",""status"":""True"",""lastProbeTime"":null,""lastTransitionTime"":""2025-02-15T08:12:56Z""},{""type"":""Ready"",""status"":""False"",""lastProbeTime"":null,""lastTransitionTime"":""2025-02-15T08:13:14Z"",""reason"":""ContainersNotReady"",""message"":""containers with unready status: [test-container-subpath-configmap-h8zg]""},{""type"":""ContainersReady"",""status"":""False"",""lastProbeTime"":null,""lastTransitionTime"":""2025-02-15T08:13:14Z"",""reason"":""ContainersNotReady"",""message"":""containers with unready status: [test-container-subpath-configmap-h8zg]""},{""type"":""PodScheduled"",""status"":""True"",""lastProbeTime"":null,""lastTransitionTime"":""2025-02-15T08:12:52Z""}],""hostIP"":""fc00:f853:ccd:e793::3"",""hostIPs"":[{""ip"":""fc00:f853:ccd:e793::3""}],""podIP"":""fd00:10:244:1::27f"",""podIPs"":[{""ip"":""fd00:10:244:1::27f""}],""startTime"":""2025-02-15T08:12:52Z"",""initContainerStatuses"":[{""name"":""init-volume-configmap-h8zg"",""state"":{""terminated"":{""exitCode"":0,""reason"":""Completed"",""startedAt"":""2025-02-15T08:12:55Z"",""finishedAt"":""2025-02-15T08:12:55Z"",""containerID"":""containerd://caf4b3bafcaec61cd9836078209eb64b0f17b158ae2b7aea8bbca9038d50a330""}},""lastState"":{},""ready"":true,""restartCount"":0,""image"":""registry.k8s.io/e2e-test-images/busybox:1.36.1-1"",""imageID"":""registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9"",""containerID"":""containerd://caf4b3bafcaec61cd9836078209eb64b0f17b158ae2b7aea8bbca9038d50a330"",""started"":false,""volumeMounts"":[{""name"":""test-volume"",""mountPath"":""/test-volume""},{""name"":""liveness-probe-volume"",""mountPath"":""/probe-volume""},{""name"":""kube-api-access-d7bjr"",""mountPath"":""/var/run/secrets/kubernetes.io/serviceaccount"",""readOnly"":true,""recursiveReadOnly"":""Disabled""}]}],""containerStatuses"":[{""name"":""test-container-subpath-configmap-h8zg"",""state"":{""terminated"":{""exitCode"":0,""reason"":""Completed"",""startedAt"":""2025-02-15T08:12:57Z"",""finishedAt"":""2025-02-15T08:13:03Z"",""containerID"":""containerd://89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1""}},""lastState"":{},""ready"":false,""restartCount"":0,""image"":""registry.k8s.io/e2e-test-images/busybox:1.36.1-1"",""imageID"":""registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9"",""containerID"":""containerd://89cdb4348fa177380e1188f0393d958858209128b3e2aa56308c1ea0c2b4bac1"",""started"":false,""volumeMounts"":[{""name"":""test-volume"",""mountPath"":""/test-volume""},{""name"":""liveness-probe-volume"",""mountPath"":""/probe-volume""},{""name"":""kube-api-access-d7bjr"",""mountPath"":""/var/run/secrets/kubernetes.io/serviceaccount"",""readOnly"":true,""recursiveReadOnly"":""Disabled""}]},{""name"":""test-container-volume-configmap-h8zg"",""state"":{""running"":{""startedAt"":""2025-02-15T08:12:58Z""}},""lastState"":{},""ready"":true,""restartCount"":0,""image"":""registry.k8s.io/e2e-test-images/busybox:1.36.1-1"",""imageID"":""registry.k8s.io/e2e-test-images/busybox@sha256:a9155b13325b2abef48e71de77bb8ac015412a566829f621d06bfae5c699b1b9"",""containerID"":""containerd://b83d07f353e6c10960e144839d90c658f1f40aea77ea78a9483620e33f98b67b"",""started"":true,""volumeMounts"":[{""name"":""test-volume"",""mountPath"":""/test-volume""},{""name"":""liveness-probe-volume"",""mountPath"":""/probe-volume""},{""name"":""kube-api-access-d7bjr"",""mountPath"":""/var/run/secrets/kubernetes.io/serviceaccount"",""readOnly"":true,""recursiveReadOnly"":""Disabled""}]}],""qosClass"":""BestEffort""}    // The ContainersToStart of the computed PodActions is empty, so no new container is created to replace the previous one.  Feb 15 08:14:31 kind-worker kubelet[285]: I0215 08:14:31.576812     285 helpers.go:104] ""Already successfully ran container, do nothing"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg"" containerName=""test-container-subpath-configmap-h8zg""  Feb 15 08:14:31 kind-worker kubelet[285]: I0215 08:14:31.576881     285 kuberuntime_manager.go:1148] ""computePodActions got for pod"" podActions=""KillPod: false, CreateSandbox: false, UpdatePodResources: false, Attempt: 0, InitContainersToStart: [], ContainersToStart: [], EphemeralContainersToStart: [],ContainersToUpdate: map[], ContainersToKill: map[]"" pod=""subpath-2059/pod-subpath-test-configmap-h8zg""  ```    **Root cause:**    The RestartPolicy of the pod is `OnFailure` and the container exited successfully.    - https://github.com/kubernetes/kubernetes/blob/c2529e844395f8895ae809fa1a5775ea8181fd20/test/e2e/storage/testsuites/subpath.go#L793  - https://github.com/kubernetes/kubernetes/blob/c2529e844395f8895ae809fa1a5775ea8181fd20/pkg/kubelet/container/helpers.go#L103  - https://github.com/kubernetes/kubernetes/blob/c2529e844395f8895ae809fa1a5775ea8181fd20/test/e2e/framework/pod/utils.go#L34    **Fix it:**    Drop `trap exit TERM` from the command to make the container exit with a non-zero exit code.    #### Which issue(s) this PR fixes:  <!--  *Automatically closes linked issue when PR is merged.  Usage: `Fixes #<issue number>`, or `Fixes (paste link of issue)`.  _If PR is about `failing-tests or flakes`, please post the related issues/tests in a comment and do not use `Fixes`_*  -->  Fixes #130268    #### Special notes for your reviewer:    #### Does this PR introduce a user-facing change?  <!--  If no, just write ""NONE"" in the release-note block below.  If yes, a release note is required:  Enter your extended release note in the block below. If the PR requires additional action from users switching to the new release, include the string ""action required"".    For more information on release notes see: https://git.k8s.io/community/contributors/guide/release-notes.md  -->  ```release-note  NONE  ```    #### Additional documentation e.g., KEPs (Kubernetes Enhancement Proposals), usage docs, etc.:    <!--  This section can be blank if this pull request does not require a release note.    When adding links which point to resources within git repositories, like  KEPs or supporting documentation, please reference a specific commit and avoid  linking directly to the master branch. This ensures that links reference a  specific point in time, rather than a document that may change over time.    See here for guidance on getting permanent links to files: https://help.github.com/en/articles/getting-permanent-links-to-files    Please use the following format for linking documentation:  - [KEP]: <link>  - [Usage]: <link>  - [Other doc]: <link>  -->  ```docs    ```"
"364","Time","Async wait","Async wait","","","","## Changes    - Increased timeout delay for the flaky test to reduce flakiness.  - Adjusted the waiting logic in `e2e_test.go` to ensure proper container health check completion.    ## Verification    - Ran the test suite multiple times locally in Gitpod and observed no flakiness.  - Confirmed that the timeout handles the observed race condition.    * [x] I added CHANGELOG entry for this change.    ## Changelog    - [#8114](https://github.com/thanos-io/thanos/pull/8114) E2E: Increased test timeout delay to reduce flakiness in container startup checks."
"365","Network","Time","Test order dependency","","","","<!--      Keep PR title verbose enough and add prefix telling      about what components it touches e.g ""query:"" or "".*:""  -->    <!--      Don't forget about CHANGELOG!        Changelog entry format:      - [#<PR-id>](<PR-URL>) Thanos <Component> ...        <PR-id> Id of your pull request.      <PR-URL> URL of your PR such as https://github.com/thanos-io/thanos/pull/<PR-id>      <Component> Component affected by your changes such as Query, Store, Receive.  -->    * [x] I added CHANGELOG entry for this change.  * [x] Change is not relevant to the end user.    ## Changes    Fixes: #8115    <!-- Enumerate changes you made -->    ## Verification    <!-- How you tested it? How do you know it works? -->"
"366","I/O","Async wait","Test order dependency","","","","<!-- Please make sure the target branch is right. In most case, the target branch should be `develop`. -->    ### Which Issue(s) This PR Fixes    <!-- Please ensure that the related issue has already been created, and [link this pull request to that issue using keywords](<https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword>) to ensure automatic closure. -->    Fixes #7614     ### Brief Description    <!-- Write a brief description for your pull request to help the maintainer understand the reasons behind your changes. -->    ### How Did You Test This Change?    ```  bazel test --config=remote  //store:src/test/java/org/apache/rocketmq/store/RocksDBMessageStoreTest --runs_per_test=1024  ```  Verify there is no failures anymore."
"367","Concurrency","Async wait","Test order dependency","","","","<!-- Please make sure the target branch is right. In most case, the target branch should be `develop`. -->    ### Which Issue(s) This PR Fixes    <!-- Please ensure that the related issue has already been created, and [link this pull request to that issue using keywords](<https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword>) to ensure automatic closure. -->    Fixes #7627    ### Brief Description    <!-- Write a brief description for your pull request to help the maintainer understand the reasons behind your changes. -->    ### How Did You Test This Change?    <!-- In order to ensure the code quality of Apache RocketMQ, we expect every pull request to have undergone thorough testing. -->"
"369","Concurrency","Async wait","Test order dependency","","","","<!-- Please make sure the target branch is right. In most case, the target branch should be `develop`. -->    ### Which Issue(s) This PR Fixes    <!-- Please ensure that the related issue has already been created, and [link this pull request to that issue using keywords](<https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword>) to ensure automatic closure. -->    Fixes #7431    ### Brief Description    Fix flaky test of DLedgerControllerTest#testBrokerLifecycleListener    ### How Did You Test This Change?    <!-- In order to ensure the code quality of Apache RocketMQ, we expect every pull request to have undergone thorough testing. -->"
"370","Unordered collections","Concurrency","Concurrency","","","","Bumps [github.com/KimMachineGun/automemlimit](https://github.com/KimMachineGun/automemlimit) from 0.7.2 to 0.7.3. <details> <summary>Release notes</summary> <p><em>Sourced from <a href=""https://github.com/KimMachineGun/automemlimit/releases"">github.com/KimMachineGun/automemlimit's releases</a>.</em></p> <blockquote> <h2>v0.7.3</h2> <h2>What's Changed</h2> <ul> <li>fix(memlimit): move goroutine execution inside refresh function by <a href=""https://github.com/KimMachineGun""><code>@‚ÄãKimMachineGun</code></a> in <a href=""https://github.com/KimMachineGun/automemlimit/commit/b2c01e82ab357d10c79031cef7b2704f225798f1"">https://github.com/KimMachineGun/automemlimit/commit/b2c01e82ab357d10c79031cef7b2704f225798f1</a></li> </ul> <p><strong>Full Changelog</strong>: <a href=""https://github.com/KimMachineGun/automemlimit/compare/v0.7.2...v0.7.3"">https://github.com/KimMachineGun/automemlimit/compare/v0.7.2...v0.7.3</a></p> </blockquote> </details> <details> <summary>Commits</summary> <ul> <li><a href=""https://github.com/KimMachineGun/automemlimit/commit/b2c01e82ab357d10c79031cef7b2704f225798f1""><code>b2c01e8</code></a> fix(memlimit): move goroutine execution inside refresh function</li> <li>See full diff in <a href=""https://github.com/KimMachineGun/automemlimit/compare/v0.7.2...v0.7.3"">compare view</a></li> </ul> </details> <br />   [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=github.com/KimMachineGun/automemlimit&package-manager=go_modules&previous-version=0.7.2&new-version=0.7.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)  Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.  [//]: # (dependabot-automerge-start) [//]: # (dependabot-automerge-end)  ---  <details> <summary>Dependabot commands and options</summary> <br />  You can trigger Dependabot actions by commenting on this PR: - `@dependabot rebase` will rebase this PR - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it - `@dependabot merge` will merge this PR after your CI passes on it - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it - `@dependabot cancel merge` will cancel a previously requested merge and block automerging - `@dependabot reopen` will reopen this PR if it is closed - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself) - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself) - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)   </details>"
"371","Concurrency","Async wait","Resource leak","","","","[PR Linked Issue] # Enhancement Description  * One-line enhancement description (can be used as a release note):    Auto remove PVCs created by StatefulSet    * Kubernetes Enhancement Proposal: [KEP-1847: Auto remove PVCs created by StatefulSet](https://github.com/kubernetes/enhancements/tree/master/keps/sig-apps/1847-autoremove-statefulset-pvcs).  * Primary contact (assignee): @mattcary  * Responsible SIGs: @sig-apps (with collaboration by @sig-storage)  * Enhancement target (which target equals to which milestone):    * Alpha release target 1.23    * Beta release target 1.27    * Stable release target 1.32      - [x] Beta    - [x] KEP (`k/enhancements`) update PR(s): https://github.com/kubernetes/enhancements/pull/3800    - [x] Code (`k/k`) update PR(s):      - https://github.com/kubernetes/kubernetes/pull/116501    - [x] Docs (`k/website`) update(s):      - https://github.com/kubernetes/website/pull/39926      - https://github.com/kubernetes/website/pull/39819  - [x] Stable    - [x] KEP (`k/enhancements`) update PR(s): https://github.com/kubernetes/enhancements/pull/4901    - [x] Code (`k/k`) update PR(s): https://github.com/kubernetes/kubernetes/pull/128247    - [x] Docs (`k/website`) update(s): https://github.com/kubernetes/website/pull/48484      _Please to keep this description up to date. This will help the Enhancement Team track efficiently the evolution of the enhancement_    Resolves [kubernetes/kubernetes#55045](https://github.com/kubernetes/kubernetes/issues/55045)"
"373","Async wait","Async wait","Network","","","","https://scans.gradle.com/s/bfgjiqwioneey/tests/task/:profiler:test/details/com.splunk.opentelemetry.profiler.snapshot.LongRunningBackgroundTaskTest/traceBackgroundThreadProfilingContinuesAfterEntrySpanEnds()?top-execution=1"
"375","Randomness","OS","OS","","","","[PR Linked Issue] <!-- ‚ö†Ô∏è‚ö†Ô∏è Do Not Delete This! bug_report_template ‚ö†Ô∏è‚ö†Ô∏è --> <!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ --> <!-- üïÆ Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions --> <!-- üîé Search existing issues to avoid creating duplicates. --> <!-- üß™ Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ --> <!-- üí° Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. --> <!-- üîß Launch with `code --disable-extensions` to check. --> Does this issue occur when all extensions are disabled?: Yes/No  <!-- ü™ì If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. --> <!-- üì£ Issues caused by an extension need to be reported directly to the extension publisher. The 'Help > Report Issue' dialog can assist with this. --> - VS Code Version:  - OS Version:   My PR is failing to be merged due to windows unit tests failing surrounding composite tokens  https://dev.azure.com/vscode/VSCode/_build/results?buildId=152385&view=logs&j=e4714b0f-e6ff-5e04-bac1-2dcbc509f151&t=5d351641-7442-59b2-8726-6d905a792029  ```   4442 passing (37s)   96 pending   1 failing    1) Composite***        ‚Ä¢ equals          ‚Ä¢ true            ‚Ä¢ composite tokens:      Error: Method not implemented.       at Test***.toString (file:///D:/a/_work/1/s/out/vs/editor/test/common/codecs/tokens/composite***.test.js:20:13)       at Base***.fullRange (file:///D:/a/_work/1/s/out/vs/editor/common/codecs/base***.js:87:54)       at new Composite*** (file:///D:/a/_work/1/s/out/vs/editor/common/codecs/composite***.js:4:21)       at new Test*** (file:///D:/a/_work/1/s/out/vs/editor/test/common/codecs/tokens/composite***.test.js:17:7)       at Context.<anonymous> (file:///D:/a/_work/1/s/out/vs/editor/test/common/codecs/tokens/composite***.test.js:126:24)       at process.processImmediate (node:internal/timers:483:21)  ```"
"378","Concurrency","Concurrency","Resource leak","","","","fix flaky test directory call  sometimes multiple runners share the same temp directory. When this happens there's a chance that the check for number of files output is (2) instead of (1). Fix this by creating a unique directory for this test."
"379","Resource leak","Time","Resource leak","","","","Reduce flakiness/sensitivity of PyFunc cleanup test.  Occasionally, unrelated-seeming changes would cause the GC-based cleanup test to fail, because `gc.collect()` did not collect all garbage. Calling `gc.collect()` twice in sequence will perform a more thorough collection, including cycles that were broken in the first call to `gc.collect()`. There is a plausible theory that the finalizers used in the `WeakValueDictionary` in `script_ops._py_funcs` could be contributing to the issue."
"380","I/O","Async wait","Concurrency","","","","Fix flaky TFRT tensor utility unit test."
"381","Time","Async wait","Async wait","","","","This test fails regularly so trying to make it a bit more robust."
"385","Test order dependency","Time","Test order dependency","","","","Fixes #50474 (hopefully)    <!--   Licensed to the Apache Software Foundation (ASF) under one   or more contributor license agreements.  See the NOTICE file   distributed with this work for additional information   regarding copyright ownership.  The ASF licenses this file   to you under the Apache License, Version 2.0 (the   ""License""); you may not use this file except in compliance   with the License.  You may obtain a copy of the License at       http://www.apache.org/licenses/LICENSE-2.0     Unless required by applicable law or agreed to in writing,   software distributed under the License is distributed on an   ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY   KIND, either express or implied.  See the License for the   specific language governing permissions and limitations   under the License.   -->    <!--  Thank you for contributing! Please make sure that your code changes  are covered with tests. And in case of new features or big changes  remember to adjust the documentation.    Feel free to ping committers for the review!    In case of an existing issue, reference it using one of the following:    closes: #ISSUE  related: #ISSUE    How to write a good git commit message:  http://chris.beams.io/posts/git-commit/  -->        <!-- Please keep an empty line above the dashes. -->  ---  **^ Add meaningful description above**  Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.  In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.  In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).  In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [airflow-core/newsfragments](https://github.com/apache/airflow/tree/main/airflow-core/newsfragments)."
"386","Async wait","Async wait","Concurrency","","","","[PR Linked Issue] ### Body  The test_listener_logs_failed_serialization is flaky - likely due to a race condition. This should be improve.    Example failure:     https://github.com/apache/airflow/actions/runs/10714765649/job/29709338209?pr=41331#step:7:5256      ```  =================================== FAILURES ===================================  ___________________ test_listener_logs_failed_serialization ____________________    self = <MagicMock name='mock.warning' id='139678763968448'>        def assert_called_once(self):          """"""assert that the mock was called only once.          """"""          if not self.call_count == 1:              msg = (""Expected '%s' to have been called once. Called %s times.%s""                     % (self._mock_name or 'mock',                        self.call_count,                        self._calls_repr()))  >           raise AssertionError(msg)  E           AssertionError: Expected 'warning' to have been called once. Called 0 times.    /usr/local/lib/python3.8/unittest/mock.py:892: AssertionError    During handling of the above exception, another exception occurred:        def test_listener_logs_failed_serialization():          listener = OpenLineageListener()          listener.log = MagicMock()          listener.adapter = OpenLineageAdapter(              client=OpenLineageClient(transport=ConsoleTransport(config=ConsoleConfig()))          )          event_time = dt.datetime.now()                fut = listener.submit_callable(              listener.adapter.dag_failed,              dag_id="""",              run_id="""",              end_date=event_time,              execution_date=threading.Thread(),              dag_run_state=DagRunState.FAILED,              task_ids=[""task_id""],              msg="""",          )          assert fut.exception(10)  >       listener.log.warning.assert_called_once()  E       AssertionError: Expected 'warning' to have been called once. Called 0 times.    tests/providers/openlineage/plugins/test_listener.py:628: AssertionError  ----------------------------- Captured stdout call -----------------------------  ```  ### Committer  - [X] I acknowledge that I am a maintainer/committer of the Apache Airflow project."
"388","Async wait","Time","Time","","","","My theory is that since 0ebea6e5c07485a36862e9b6e2be18d1694ad2c5, the saving of objects has become slightly slower  This caused some failures in the selenium test suite: https://github.com/django/django/actions/runs/13826117388/job/38698352291"
"389","Async wait","Unordered collections","Test order dependency","","","","This fixes a failure that I have with #16965."
"392","OS","Async wait","Test order dependency","","","","[PR Linked Issue] ### Test  `test/async-hooks/test-improper-order.js`  ### Platform  AIX  ### Console output  ```console not ok 68 async-hooks/test-improper-order   ---   duration_ms: 459.21600   severity: fail   exitcode: 1   stack: |-     node:assert:94       throw new AssertionError(obj);       ^          AssertionError [ERR_ASSERTION]: Expected values to be strictly equal:          null !== 1              at ChildProcess.<anonymous> (/home/iojs/build/workspace/node-test-commit-aix/nodes/aix72-ppc64/test/async-hooks/test-improper-order.js:55:12)         at ChildProcess.<anonymous> (/home/iojs/build/workspace/node-test-commit-aix/nodes/aix72-ppc64/test/common/index.js:437:15)         at ChildProcess.emit (node:events:507:28)         at maybeClose (node:internal/child_process:1101:16)         at ChildProcess._handle.onexit (node:internal/child_process:305:5) {       generatedMessage: true,       code: 'ERR_ASSERTION',       actual: null,       expected: 1,       operator: 'strictEqual'     }          Node.js v25.0.0-pre   ... ```  ### Build links  - https://ci.nodejs.org/job/node-test-commit-aix/57496/nodes=aix72-ppc64/testReport/junit/(root)/async-hooks/test_improper_order/  ### Additional information  This flake is appearing in the reliability report 3 times daily from 2025-05-31 - https://github.com/nodejs/reliability/issues/1217 till today 2025-06-03 - https://github.com/nodejs/reliability/issues/1220.  The same strategy in https://github.com/nodejs/node/pull/58478 can be used to deflake this test."
"393","OS","Resource leak","Resource leak","","","","[PR Linked Issue] ### Test  `test-blob-slice-with-large-size`  ### Platform  SmartOS  ### Console output  ```console --- duration_ms: 290.507 exitcode: 1 severity: fail stack: |-   /home/iojs/build/workspace/node-test-commit-smartos/nodes/smartos23-x64/test/pummel/test-blob-slice-with-large-size.js:18       throw e;       ^    RangeError: Array buffer allocation failed       at new ArrayBuffer (<anonymous>)       at new Uint8Array (<anonymous>)       at new FastBuffer (node:internal/buffer:961:5)       at createUnsafeBuffer (node:internal/buffer:1097:12)       at allocate (node:buffer:445:10)       at Function.allocUnsafe (node:buffer:410:10)       at Object.<anonymous> (/home/iojs/build/workspace/node-test-commit-smartos/nodes/smartos23-x64/test/pummel/test-blob-slice-with-large-size.js:12:22)       at Module._compile (node:internal/modules/cjs/loader:1734:14)       at Object..js (node:internal/modules/cjs/loader:1899:10)       at Module.load (node:internal/modules/cjs/loader:1469:32)    Node.js v24.0.0-pre ```  ### Build links  - https://ci.nodejs.org/job/node-test-commit-smartos/59405/nodes=smartos23-x64/testReport/junit/(root)/pummel/test_blob_slice_with_large_size/  ### Additional information  It seems to reproduce quite rarely"
"394","Async wait","Time","Resource leak","","","","Refs #56190    This PR does two things in the specific `test` case that is flaky:    - Make the `composedSignal` a weak ref so the test won't hold any reference that could keep that variable from being GCed.  - Add `gcUntil` so it will make more calls to `global.gc`. Precisely, until that condition is reached or a maximum number of attempts is hit."
"413","Async wait","Time","Time","","","","<!--- Note to EXTERNAL Contributors -->  <!-- Thanks for opening a PR!   If it is a significant code change, please **make sure there is an open issue** for this.   We work best with you when we have accepted the idea first before you code. -->    <!--- For ALL Contributors üëá -->    ## What was changed  <!-- Describe what has changed in this PR -->    Bumped to Go 1.25 to use the new `synctest.Test` primitive to run deterministic timing tests.    Tip: use `Hide Whitespace` option for reviewing.    ## Why?  <!-- Tell your future self why have you made these changes -->    `TestRunDurationWithoutTimeout` is flaky - example:  https://github.com/temporalio/omes/actions/runs/17052148233/job/48342124492?pr=179#step:4:125    ## Checklist  <!--- add/delete as needed --->    1. Closes <!-- add issue number here -->    2. How was this tested:  <!--- Please describe how you tested your changes/how we can test them -->    3. Any docs updates needed?  <!--- update README if applicable        or point out where to update docs.temporal.io -->"
"415","Async wait","Async wait","Time","","","","# Description  Fixes 3 flaky tests.    # Changes  - `local_node_store_filtered_solutions`      - it failed due to timeouts => increased the http delay buffer to give a bit of wiggle room      - sometimes an auction ran while only 1 of the 2 solutions was included => configure hardcoded solver solutions after both orders have been included in the auction  - `local_node_partially_fillable_pool`      - solver got deny listed because it failed to produce a working solution for some reason          - updated the flags to enable that feature to work like `--flag=true` instead of `--flag` (to enable)          - disabled the feature on all tests except tests specifically for those features  - `local_node_replace_order`      - order got settled before it could be replaced          - ban solver until the original order is no longer inside the auction          - allow unverified quotes for that test due to the banned solver account    ## How to test  used the flaky test runner  - ran all local node tests for 2h -> ~30 successful executions  - `local_node_replace_order` -> flaky test [job](https://github.com/cowprotocol/services/actions/runs/17316920910/job/49161443945) with 369 successful runs"
"416","Async wait","Async wait","Test order dependency","","","","**Description**    Closes #1142"
"418","Randomness","Async wait","Network","","","","Experiment with a new background task library that uses Redis Streams"
"420","Async wait","Time","Test order dependency","","","","Fixes #13526"
"421","Concurrency","Randomness","Randomness","","","","### What changes are proposed in this pull request?    Fix the flaky test in the two-choice random cache eviction policy    ### Why are the changes needed?    As the test is flaky, it will influence other PRs.    ### Does this PR introduce any user facing changes?    No."
"428","Async wait","Concurrency","Concurrency","","","","<!--  Thanks for sending a pull request!  Here are some tips for you:    1. If this is your first time, please read our contributor guidelines: https://git.k8s.io/community/contributors/guide/first-contribution.md#your-first-contribution and developer guide https://git.k8s.io/community/contributors/devel/development.md#development-guide  2. Please label this pull request according to what type of issue you are addressing, especially if this is a release targeted pull request. For reference on required PR/issue labels, read here:  https://git.k8s.io/community/contributors/devel/sig-release/release.md#issuepr-kind-label  3. Ensure you have added or ran the appropriate tests for your PR: https://git.k8s.io/community/contributors/devel/sig-testing/testing.md  4. If you want *faster* PR reviews, read how: https://git.k8s.io/community/contributors/guide/pull-requests.md#best-practices-for-faster-reviews  5. If the PR is unfinished, see how to mark it: https://git.k8s.io/community/contributors/guide/pull-requests.md#marking-unfinished-pull-requests  -->    #### What type of PR is this?  /kind flake  <!--  Add one of the following kinds:  /kind bug  /kind cleanup  /kind documentation  /kind feature    Optionally add one or more of the following kinds if applicable:  /kind api-change  /kind deprecation  /kind failing-test  /kind flake  /kind regression  -->    #### What this PR does / why we need it:  This pr fixes a race problem introduced by #128642    When using `exit 0` as the command of a container. After the container is terminated,`finishedAt - startedAt` can be -1 second, which violates the validation after.    Related job: https://prow.k8s.io/view/gs/kubernetes-ci-logs/pr-logs/pull/129680/pull-kubernetes-e2e-gce/1933002039273459712  #### Which issue(s) this PR is related to:  <!--  Please link relevant issues to help with tracking.    To automatically close the linked issue(s) when this PR is merged,  add the word ""Fixes"" before the issue number or link.  Do not use ""Fixes"" if the PR is of kind `failing-test` or `flake`.    Reference KEPs when applicable in addition to specific issues.    Examples:  Fixes #<issue number>  <issue link> (issue in a different repository)  KEP: https://github.com/kubernetes/enhancements/issues/<kep-issue-number>    If there is no associated issue, then write ""N/A"".  -->    #### Special notes for your reviewer:    #### Does this PR introduce a user-facing change?  <!--  If no, just write ""NONE"" in the release-note block below.  If yes, a release note is required:  Enter your extended release note in the block below. If the PR requires additional action from users switching to the new release, include the string ""action required"".    For more information on release notes see: https://git.k8s.io/community/contributors/guide/release-notes.md  -->  ```release-note  NONE  ```    #### Additional documentation e.g., KEPs (Kubernetes Enhancement Proposals), usage docs, etc.:    <!--  This section can be blank if this pull request does not require a release note.    When adding links which point to resources within git repositories, like  KEPs or supporting documentation, please reference a specific commit and avoid  linking directly to the master branch. This ensures that links reference a  specific point in time, rather than a document that may change over time.    See here for guidance on getting permanent links to files: https://help.github.com/en/articles/getting-permanent-links-to-files    Please use the following format for linking documentation:  - [KEP]: <link>  - [Usage]: <link>  - [Other doc]: <link>  -->  ```docs    ```"
"430","Randomness","Randomness","Network","","","","The bucket counts can vary run to run. Also don't hardcode the port"
"431","Async wait","Concurrency","Network","","","","There's a TOCTOU issue that can happen when selecting unused ports for the server to use (we get assigned an unused port by the OS, and between then and when the server actually binds to the port another test steals it). Improve this by checking if the server existed soon after setup, and if so we retry starting it. Client connection can also fail spuriously (in local testing) so added a retry mechanism.    This also fixes a hang, where if the server exited (almost always due to the issue described above) before we connected to it, attempting to connect our client ZMQ sockets to it would just hang. To resolve this, I added a timeout so we can't wait forever."
